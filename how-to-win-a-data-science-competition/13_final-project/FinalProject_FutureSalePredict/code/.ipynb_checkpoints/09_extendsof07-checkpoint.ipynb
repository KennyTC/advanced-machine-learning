{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from numpy import loadtxt\n",
    "import time\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "kernel_with_output = True\n",
    "np.random.seed(10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', 231)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation = False\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    # Feature engineering list\n",
    "    new_features = []\n",
    "    enable_feature_idea = [True, True, True, True, True, True, True, True, True, True]\n",
    "    # Some parameters(maybe add more periods, score will be better) [1,2,3,12]\n",
    "    lookback_range = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int16)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    item =pd.read_csv(\"../data/items.csv\")\n",
    "    item_cat = pd.read_csv(\"../data/item_categories.csv\")\n",
    "#     df_shops = pd.read_csv(\"../data/shops.csv\")\n",
    "    sale_train = pd.read_csv(\"../data/sales_train.csv.gz\")\n",
    "    test = pd.read_csv(\"../data/test.csv.gz\")\n",
    "    temp = pd.read_csv(\"../data/sample_submission.csv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8812244, 124)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_set = pd.read_pickle(\"../results/07/all_data_traintest_012367.pkl\")\n",
    "train_test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>prev_shopitem_sales_1</th>\n",
       "      <th>prev_shopitem_sales_2</th>\n",
       "      <th>prev_shopitem_sales_3</th>\n",
       "      <th>prev_shopitem_sales_4</th>\n",
       "      <th>prev_shopitem_sales_5</th>\n",
       "      <th>prev_shopitem_sales_6</th>\n",
       "      <th>prev_shopitem_sales_7</th>\n",
       "      <th>prev_shopitem_sales_8</th>\n",
       "      <th>prev_shopitem_sales_9</th>\n",
       "      <th>prev_shopitem_sales_10</th>\n",
       "      <th>prev_shopitem_sales_11</th>\n",
       "      <th>prev_shopitem_sales_12</th>\n",
       "      <th>prev_item_sales_1</th>\n",
       "      <th>prev_item_sales_2</th>\n",
       "      <th>prev_item_sales_3</th>\n",
       "      <th>prev_item_sales_4</th>\n",
       "      <th>prev_item_sales_5</th>\n",
       "      <th>prev_item_sales_6</th>\n",
       "      <th>prev_item_sales_7</th>\n",
       "      <th>prev_item_sales_8</th>\n",
       "      <th>prev_item_sales_9</th>\n",
       "      <th>prev_item_sales_10</th>\n",
       "      <th>prev_item_sales_11</th>\n",
       "      <th>prev_item_sales_12</th>\n",
       "      <th>prev_shopitem_price_1</th>\n",
       "      <th>prev_shopitem_price_2</th>\n",
       "      <th>prev_shopitem_price_3</th>\n",
       "      <th>prev_shopitem_price_4</th>\n",
       "      <th>prev_shopitem_price_5</th>\n",
       "      <th>prev_shopitem_price_6</th>\n",
       "      <th>prev_shopitem_price_7</th>\n",
       "      <th>prev_shopitem_price_8</th>\n",
       "      <th>prev_shopitem_price_9</th>\n",
       "      <th>prev_shopitem_price_10</th>\n",
       "      <th>prev_shopitem_price_11</th>\n",
       "      <th>prev_shopitem_price_12</th>\n",
       "      <th>prev_item_price_1</th>\n",
       "      <th>prev_item_price_2</th>\n",
       "      <th>prev_item_price_3</th>\n",
       "      <th>prev_item_price_4</th>\n",
       "      <th>prev_item_price_5</th>\n",
       "      <th>prev_item_price_6</th>\n",
       "      <th>...</th>\n",
       "      <th>_prev_shopitem_sales_19</th>\n",
       "      <th>_prev_shopitem_sales_20</th>\n",
       "      <th>_prev_shopitem_sales_21</th>\n",
       "      <th>_prev_shopitem_sales_22</th>\n",
       "      <th>_prev_shopitem_sales_23</th>\n",
       "      <th>_prev_shopitem_sales_24</th>\n",
       "      <th>_prev_shopitem_sales_25</th>\n",
       "      <th>_prev_shopitem_sales_26</th>\n",
       "      <th>_prev_shopitem_sales_27</th>\n",
       "      <th>_prev_shopitem_sales_28</th>\n",
       "      <th>_prev_shopitem_sales_29</th>\n",
       "      <th>_prev_shopitem_sales_30</th>\n",
       "      <th>_prev_shopitem_sales_31</th>\n",
       "      <th>_prev_shopitem_sales_32</th>\n",
       "      <th>_prev_shopitem_sales_33</th>\n",
       "      <th>last_sale_shop_item</th>\n",
       "      <th>_prev_item_sales_1</th>\n",
       "      <th>_prev_item_sales_2</th>\n",
       "      <th>_prev_item_sales_3</th>\n",
       "      <th>_prev_item_sales_4</th>\n",
       "      <th>_prev_item_sales_5</th>\n",
       "      <th>_prev_item_sales_6</th>\n",
       "      <th>_prev_item_sales_7</th>\n",
       "      <th>_prev_item_sales_8</th>\n",
       "      <th>_prev_item_sales_9</th>\n",
       "      <th>_prev_item_sales_10</th>\n",
       "      <th>_prev_item_sales_11</th>\n",
       "      <th>_prev_item_sales_12</th>\n",
       "      <th>_prev_item_sales_13</th>\n",
       "      <th>_prev_item_sales_14</th>\n",
       "      <th>_prev_item_sales_15</th>\n",
       "      <th>_prev_item_sales_16</th>\n",
       "      <th>_prev_item_sales_17</th>\n",
       "      <th>_prev_item_sales_18</th>\n",
       "      <th>_prev_item_sales_19</th>\n",
       "      <th>_prev_item_sales_20</th>\n",
       "      <th>_prev_item_sales_21</th>\n",
       "      <th>_prev_item_sales_22</th>\n",
       "      <th>_prev_item_sales_23</th>\n",
       "      <th>_prev_item_sales_24</th>\n",
       "      <th>_prev_item_sales_25</th>\n",
       "      <th>_prev_item_sales_26</th>\n",
       "      <th>_prev_item_sales_27</th>\n",
       "      <th>_prev_item_sales_28</th>\n",
       "      <th>_prev_item_sales_29</th>\n",
       "      <th>_prev_item_sales_30</th>\n",
       "      <th>_prev_item_sales_31</th>\n",
       "      <th>_prev_item_sales_32</th>\n",
       "      <th>_prev_item_sales_33</th>\n",
       "      <th>last_sale_item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22151</td>\n",
       "      <td>399.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5603</td>\n",
       "      <td>699.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5587</td>\n",
       "      <td>199.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5613</td>\n",
       "      <td>5571.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  date_block_num  item_category_id  item_cnt_month  \\\n",
       "0           0             0               0                37             1.0   \n",
       "1           1             1               0                40             2.0   \n",
       "2           2             2               0                 5             1.0   \n",
       "3           3             3               0                 5             2.0   \n",
       "4           4             4               0                 2             1.0   \n",
       "\n",
       "   item_id  item_price  shop_id  prev_shopitem_sales_1  prev_shopitem_sales_2  \\\n",
       "0    22154       999.0       59                    0.0                    0.0   \n",
       "1    22151       399.0       59                    0.0                    0.0   \n",
       "2     5603       699.0       59                    0.0                    0.0   \n",
       "3     5587       199.0       59                    0.0                    0.0   \n",
       "4     5613      5571.0       59                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_3  prev_shopitem_sales_4  prev_shopitem_sales_5  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_6  prev_shopitem_sales_7  prev_shopitem_sales_8  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_9  prev_shopitem_sales_10  prev_shopitem_sales_11  \\\n",
       "0                    0.0                     0.0                     0.0   \n",
       "1                    0.0                     0.0                     0.0   \n",
       "2                    0.0                     0.0                     0.0   \n",
       "3                    0.0                     0.0                     0.0   \n",
       "4                    0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_shopitem_sales_12  prev_item_sales_1 prev_item_sales_2  \\\n",
       "0                     0.0                0.0                 0   \n",
       "1                     0.0                0.0                 0   \n",
       "2                     0.0                0.0                 0   \n",
       "3                     0.0                0.0                 0   \n",
       "4                     0.0                0.0                 0   \n",
       "\n",
       "   prev_item_sales_3  prev_item_sales_4  prev_item_sales_5  prev_item_sales_6  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_7  prev_item_sales_8  prev_item_sales_9  \\\n",
       "0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_10  prev_item_sales_11  prev_item_sales_12  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   prev_shopitem_price_1  prev_shopitem_price_2  prev_shopitem_price_3  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_4  prev_shopitem_price_5  prev_shopitem_price_6  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_7  prev_shopitem_price_8  prev_shopitem_price_9  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "3                    0.0                    0.0                    0.0   \n",
       "4                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_10  prev_shopitem_price_11  prev_shopitem_price_12  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "3                     0.0                     0.0                     0.0   \n",
       "4                     0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_item_price_1  prev_item_price_2  prev_item_price_3  prev_item_price_4  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_price_5  prev_item_price_6  ...  _prev_shopitem_sales_19  \\\n",
       "0                0.0                0.0  ...                      0.0   \n",
       "1                0.0                0.0  ...                      0.0   \n",
       "2                0.0                0.0  ...                      0.0   \n",
       "3                0.0                0.0  ...                      0.0   \n",
       "4                0.0                0.0  ...                      0.0   \n",
       "\n",
       "   _prev_shopitem_sales_20  _prev_shopitem_sales_21  _prev_shopitem_sales_22  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   _prev_shopitem_sales_23  _prev_shopitem_sales_24  _prev_shopitem_sales_25  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   _prev_shopitem_sales_26  _prev_shopitem_sales_27  _prev_shopitem_sales_28  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   _prev_shopitem_sales_29  _prev_shopitem_sales_30  _prev_shopitem_sales_31  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   _prev_shopitem_sales_32  _prev_shopitem_sales_33  last_sale_shop_item  \\\n",
       "0                      0.0                      0.0                  NaN   \n",
       "1                      0.0                      0.0                  NaN   \n",
       "2                      0.0                      0.0                  NaN   \n",
       "3                      0.0                      0.0                  NaN   \n",
       "4                      0.0                      0.0                  NaN   \n",
       "\n",
       "   _prev_item_sales_1  _prev_item_sales_2  _prev_item_sales_3  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   _prev_item_sales_4  _prev_item_sales_5  _prev_item_sales_6  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   _prev_item_sales_7  _prev_item_sales_8  _prev_item_sales_9  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "3                 0.0                 0.0                 0.0   \n",
       "4                 0.0                 0.0                 0.0   \n",
       "\n",
       "   _prev_item_sales_10  _prev_item_sales_11  _prev_item_sales_12  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_13  _prev_item_sales_14  _prev_item_sales_15  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_16  _prev_item_sales_17  _prev_item_sales_18  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_19  _prev_item_sales_20  _prev_item_sales_21  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_22  _prev_item_sales_23  _prev_item_sales_24  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_25  _prev_item_sales_26  _prev_item_sales_27  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_28  _prev_item_sales_29  _prev_item_sales_30  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   _prev_item_sales_31  _prev_item_sales_32  _prev_item_sales_33  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   last_sale_item  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   int16\n",
       "Unnamed: 0.1                 int16\n",
       "date_block_num               int16\n",
       "item_category_id             int16\n",
       "item_cnt_month             float32\n",
       "item_id                      int16\n",
       "item_price                 float32\n",
       "shop_id                      int16\n",
       "prev_shopitem_sales_1      float32\n",
       "prev_shopitem_sales_2      float32\n",
       "prev_shopitem_sales_3      float32\n",
       "prev_shopitem_sales_4      float32\n",
       "prev_shopitem_sales_5      float32\n",
       "prev_shopitem_sales_6      float32\n",
       "prev_shopitem_sales_7      float32\n",
       "prev_shopitem_sales_8      float32\n",
       "prev_shopitem_sales_9      float32\n",
       "prev_shopitem_sales_10     float32\n",
       "prev_shopitem_sales_11     float32\n",
       "prev_shopitem_sales_12     float32\n",
       "prev_item_sales_1          float32\n",
       "prev_item_sales_2           object\n",
       "prev_item_sales_3          float32\n",
       "prev_item_sales_4          float32\n",
       "prev_item_sales_5          float32\n",
       "prev_item_sales_6          float32\n",
       "prev_item_sales_7          float32\n",
       "prev_item_sales_8          float32\n",
       "prev_item_sales_9          float32\n",
       "prev_item_sales_10         float32\n",
       "prev_item_sales_11         float32\n",
       "prev_item_sales_12         float32\n",
       "prev_shopitem_price_1      float32\n",
       "prev_shopitem_price_2      float32\n",
       "prev_shopitem_price_3      float32\n",
       "prev_shopitem_price_4      float32\n",
       "prev_shopitem_price_5      float32\n",
       "prev_shopitem_price_6      float32\n",
       "prev_shopitem_price_7      float32\n",
       "prev_shopitem_price_8      float32\n",
       "prev_shopitem_price_9      float32\n",
       "prev_shopitem_price_10     float32\n",
       "prev_shopitem_price_11     float32\n",
       "prev_shopitem_price_12     float32\n",
       "prev_item_price_1          float32\n",
       "prev_item_price_2          float32\n",
       "prev_item_price_3          float32\n",
       "prev_item_price_4          float32\n",
       "prev_item_price_5          float32\n",
       "prev_item_price_6          float32\n",
       "prev_item_price_7          float32\n",
       "prev_item_price_8          float32\n",
       "prev_item_price_9          float32\n",
       "prev_item_price_10         float32\n",
       "prev_item_price_11         float32\n",
       "prev_item_price_12         float32\n",
       "_prev_shopitem_sales_1     float32\n",
       "_prev_shopitem_sales_2     float32\n",
       "_prev_shopitem_sales_3     float32\n",
       "_prev_shopitem_sales_4     float32\n",
       "_prev_shopitem_sales_5     float32\n",
       "_prev_shopitem_sales_6     float32\n",
       "_prev_shopitem_sales_7     float32\n",
       "_prev_shopitem_sales_8     float32\n",
       "_prev_shopitem_sales_9     float32\n",
       "_prev_shopitem_sales_10    float32\n",
       "_prev_shopitem_sales_11    float32\n",
       "_prev_shopitem_sales_12    float32\n",
       "_prev_shopitem_sales_13    float32\n",
       "_prev_shopitem_sales_14    float32\n",
       "_prev_shopitem_sales_15    float32\n",
       "_prev_shopitem_sales_16    float32\n",
       "_prev_shopitem_sales_17    float32\n",
       "_prev_shopitem_sales_18    float32\n",
       "_prev_shopitem_sales_19    float32\n",
       "_prev_shopitem_sales_20    float32\n",
       "_prev_shopitem_sales_21    float32\n",
       "_prev_shopitem_sales_22    float32\n",
       "_prev_shopitem_sales_23    float32\n",
       "_prev_shopitem_sales_24    float32\n",
       "_prev_shopitem_sales_25    float32\n",
       "_prev_shopitem_sales_26    float32\n",
       "_prev_shopitem_sales_27    float32\n",
       "_prev_shopitem_sales_28    float32\n",
       "_prev_shopitem_sales_29    float32\n",
       "_prev_shopitem_sales_30    float32\n",
       "_prev_shopitem_sales_31    float32\n",
       "_prev_shopitem_sales_32    float32\n",
       "_prev_shopitem_sales_33    float32\n",
       "last_sale_shop_item        float32\n",
       "_prev_item_sales_1         float32\n",
       "_prev_item_sales_2         float32\n",
       "_prev_item_sales_3         float32\n",
       "_prev_item_sales_4         float32\n",
       "_prev_item_sales_5         float32\n",
       "_prev_item_sales_6         float32\n",
       "_prev_item_sales_7         float32\n",
       "_prev_item_sales_8         float32\n",
       "_prev_item_sales_9         float32\n",
       "_prev_item_sales_10        float32\n",
       "_prev_item_sales_11        float32\n",
       "_prev_item_sales_12        float32\n",
       "_prev_item_sales_13        float32\n",
       "_prev_item_sales_14        float32\n",
       "_prev_item_sales_15        float32\n",
       "_prev_item_sales_16        float32\n",
       "_prev_item_sales_17        float32\n",
       "_prev_item_sales_18        float32\n",
       "_prev_item_sales_19        float32\n",
       "_prev_item_sales_20        float32\n",
       "_prev_item_sales_21        float32\n",
       "_prev_item_sales_22        float32\n",
       "_prev_item_sales_23        float32\n",
       "_prev_item_sales_24        float32\n",
       "_prev_item_sales_25        float32\n",
       "_prev_item_sales_26        float32\n",
       "_prev_item_sales_27        float32\n",
       "_prev_item_sales_28        float32\n",
       "_prev_item_sales_29        float32\n",
       "_prev_item_sales_30        float32\n",
       "_prev_item_sales_31        float32\n",
       "_prev_item_sales_32        float32\n",
       "_prev_item_sales_33        float32\n",
       "last_sale_item             float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "782633"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "4691435"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_set.head()\n",
    "train_test_set.dtypes\n",
    "train_test_set.last_sale_item.isna().sum()\n",
    "train_test_set.last_sale_shop_item.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set.loc[train_test_set.prev_item_sales_2==\"0*0\",\"prev_item_sales_2\"] = 0.0\n",
    "train_test_set.prev_item_sales_2 = train_test_set.prev_item_sales_2.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    current = time.time()    \n",
    "    features_added = [col for col in train_test_set if col.startswith(\"_prev\") or col.startswith(\"prev\")]\n",
    "    baseline_features = [\"shop_id\", \"item_id\", \"item_category_id\", \"date_block_num\"]+ features_added\n",
    "    train_test_set[\"item_cnt_month\"] = train_test_set.item_cnt_month.fillna(0).clip(0,20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = train_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = all_data[\"date_block_num\"]\n",
    "last_block = dates.max() # last_block 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_first_level_total = time.perf_counter()\n",
    "scoringMethod = 'r2'\n",
    "num_first_level_models = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train meta-features M = 15 (12 + 15 = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_to_generate_meta_features = range(27,last_block +1)\n",
    "mask = dates.isin(months_to_generate_meta_features)\n",
    "Target = 'item_cnt_month'\n",
    "y_all_level2 = all_data[Target][mask].values # choose item_cnt_month where date_block_num from 27..34\n",
    "X_all_level2 = np.zeros([y_all_level2.shape[0], num_first_level_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_start = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month27\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.974260\n",
      "Test RMSE for SGDRegressor is 0.992076\n",
      "SGDRegressor runs for 9.56 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.857592\n",
      "Test RMSE for lightgbm is 0.925844\n",
      "lightgbm runs for 418.89 seconds.\n",
      "\n",
      "Training Model 2: keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\KennyT\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/5\n",
      "3746814/3746814 [==============================] - ETA: 1:22 - loss: 1.6491 - mean_squared_error: 1.64 - ETA: 44s - loss: 1.6355 - mean_squared_error: 1.6355 - ETA: 32s - loss: 1.6548 - mean_squared_error: 1.654 - ETA: 26s - loss: 1.6768 - mean_squared_error: 1.676 - ETA: 22s - loss: 1.6441 - mean_squared_error: 1.644 - ETA: 19s - loss: 1.6393 - mean_squared_error: 1.639 - ETA: 17s - loss: 1.6322 - mean_squared_error: 1.632 - ETA: 16s - loss: 1.6194 - mean_squared_error: 1.619 - ETA: 15s - loss: 1.6286 - mean_squared_error: 1.628 - ETA: 14s - loss: 1.6282 - mean_squared_error: 1.628 - ETA: 13s - loss: 1.6251 - mean_squared_error: 1.625 - ETA: 12s - loss: 1.6234 - mean_squared_error: 1.623 - ETA: 11s - loss: 1.6236 - mean_squared_error: 1.623 - ETA: 11s - loss: 1.6243 - mean_squared_error: 1.624 - ETA: 10s - loss: 1.6246 - mean_squared_error: 1.624 - ETA: 10s - loss: 1.6283 - mean_squared_error: 1.628 - ETA: 10s - loss: 1.6322 - mean_squared_error: 1.632 - ETA: 9s - loss: 1.6313 - mean_squared_error: 1.631 - ETA: 9s - loss: 1.6350 - mean_squared_error: 1.63 - ETA: 9s - loss: 1.6346 - mean_squared_error: 1.63 - ETA: 8s - loss: 1.6375 - mean_squared_error: 1.63 - ETA: 8s - loss: 1.6418 - mean_squared_error: 1.64 - ETA: 8s - loss: 1.6397 - mean_squared_error: 1.63 - ETA: 7s - loss: 1.6407 - mean_squared_error: 1.64 - ETA: 7s - loss: 1.6441 - mean_squared_error: 1.64 - ETA: 7s - loss: 1.6483 - mean_squared_error: 1.64 - ETA: 7s - loss: 1.6467 - mean_squared_error: 1.64 - ETA: 6s - loss: 1.6425 - mean_squared_error: 1.64 - ETA: 6s - loss: 1.6431 - mean_squared_error: 1.64 - ETA: 6s - loss: 1.6446 - mean_squared_error: 1.64 - ETA: 6s - loss: 1.6447 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6459 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6456 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6442 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6446 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6423 - mean_squared_error: 1.64 - ETA: 5s - loss: 1.6440 - mean_squared_error: 1.64 - ETA: 4s - loss: 1.6440 - mean_squared_error: 1.64 - ETA: 4s - loss: 1.6433 - mean_squared_error: 1.64 - ETA: 4s - loss: 1.6430 - mean_squared_error: 1.64 - ETA: 4s - loss: 1.6415 - mean_squared_error: 1.64 - ETA: 4s - loss: 1.6420 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6417 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6435 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6420 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6421 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6412 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6439 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6424 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6416 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6411 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6406 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6437 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6430 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6418 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6403 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6387 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6369 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6347 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6335 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6343 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6331 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6348 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6374 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6370 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6354 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6360 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6346 - mean_squared_error: 1.63 - 10s 3us/step - loss: 1.6347 - mean_squared_error: 1.6347\n",
      "Epoch 2/5\n",
      "3746814/3746814 [==============================] - ETA: 29s - loss: 1.6253 - mean_squared_error: 1.625 - ETA: 17s - loss: 1.6053 - mean_squared_error: 1.605 - ETA: 14s - loss: 1.6060 - mean_squared_error: 1.606 - ETA: 12s - loss: 1.6092 - mean_squared_error: 1.609 - ETA: 11s - loss: 1.5875 - mean_squared_error: 1.587 - ETA: 10s - loss: 1.6046 - mean_squared_error: 1.604 - ETA: 10s - loss: 1.6018 - mean_squared_error: 1.601 - ETA: 9s - loss: 1.6231 - mean_squared_error: 1.623 - ETA: 9s - loss: 1.6233 - mean_squared_error: 1.62 - ETA: 9s - loss: 1.6184 - mean_squared_error: 1.61 - ETA: 8s - loss: 1.6139 - mean_squared_error: 1.61 - ETA: 8s - loss: 1.6162 - mean_squared_error: 1.61 - ETA: 8s - loss: 1.6241 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6158 - mean_squared_error: 1.61 - ETA: 7s - loss: 1.6226 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6161 - mean_squared_error: 1.61 - ETA: 7s - loss: 1.6125 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6119 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6153 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6153 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6195 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6271 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6305 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6298 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6296 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6264 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6263 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6254 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6261 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6270 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6261 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6250 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6222 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6184 - mean_squared_error: 1.61 - ETA: 4s - loss: 1.6229 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6201 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6199 - mean_squared_error: 1.61 - ETA: 4s - loss: 1.6219 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6202 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6199 - mean_squared_error: 1.61 - ETA: 3s - loss: 1.6200 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6195 - mean_squared_error: 1.61 - ETA: 3s - loss: 1.6205 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6255 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6265 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6261 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6266 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6285 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6288 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6294 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6307 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6310 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6301 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6289 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6290 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6272 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6252 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6268 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6262 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6264 - mean_squared_error: 1.62 - ETA: 0s - loss: 1.6287 - mean_squared_error: 1.62 - ETA: 0s - loss: 1.6271 - mean_squared_error: 1.62 - ETA: 0s - loss: 1.6291 - mean_squared_error: 1.62 - ETA: 0s - loss: 1.6317 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6321 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6326 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6325 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6340 - mean_squared_error: 1.63 - 9s 2us/step - loss: 1.6347 - mean_squared_error: 1.6347\n",
      "Epoch 3/5\n",
      "3746814/3746814 [==============================] - ETA: 29s - loss: 1.6371 - mean_squared_error: 1.637 - ETA: 18s - loss: 1.6005 - mean_squared_error: 1.600 - ETA: 14s - loss: 1.5762 - mean_squared_error: 1.576 - ETA: 13s - loss: 1.5946 - mean_squared_error: 1.594 - ETA: 11s - loss: 1.5872 - mean_squared_error: 1.587 - ETA: 10s - loss: 1.6046 - mean_squared_error: 1.604 - ETA: 10s - loss: 1.6212 - mean_squared_error: 1.621 - ETA: 9s - loss: 1.6210 - mean_squared_error: 1.621 - ETA: 9s - loss: 1.6165 - mean_squared_error: 1.61 - ETA: 9s - loss: 1.6136 - mean_squared_error: 1.61 - ETA: 8s - loss: 1.6128 - mean_squared_error: 1.61 - ETA: 8s - loss: 1.6006 - mean_squared_error: 1.60 - ETA: 8s - loss: 1.6019 - mean_squared_error: 1.60 - ETA: 7s - loss: 1.6121 - mean_squared_error: 1.61 - ETA: 7s - loss: 1.6201 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6197 - mean_squared_error: 1.61 - ETA: 7s - loss: 1.6160 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6180 - mean_squared_error: 1.61 - ETA: 6s - loss: 1.6235 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6290 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6239 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6233 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6241 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6265 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6219 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6225 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6251 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6270 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6281 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6273 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6299 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6304 - mean_squared_error: 1.63 - ETA: 4s - loss: 1.6320 - mean_squared_error: 1.63 - ETA: 4s - loss: 1.6359 - mean_squared_error: 1.63 - ETA: 4s - loss: 1.6392 - mean_squared_error: 1.63 - ETA: 4s - loss: 1.6410 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6377 - mean_squared_error: 1.63 - ETA: 3s - loss: 1.6414 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6409 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6407 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6403 - mean_squared_error: 1.64 - ETA: 3s - loss: 1.6392 - mean_squared_error: 1.63 - ETA: 3s - loss: 1.6393 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6395 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6403 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6401 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6420 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6430 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6435 - mean_squared_error: 1.64 - ETA: 2s - loss: 1.6441 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6409 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6416 - mean_squared_error: 1.64 - ETA: 1s - loss: 1.6399 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6387 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6393 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6394 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6383 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6368 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6359 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6355 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6341 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6354 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6353 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6349 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6355 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6365 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6359 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6355 - mean_squared_error: 1.63 - 8s 2us/step - loss: 1.6347 - mean_squared_error: 1.6347\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3746814/3746814 [==============================] - ETA: 30s - loss: 1.6872 - mean_squared_error: 1.687 - ETA: 19s - loss: 1.6669 - mean_squared_error: 1.666 - ETA: 15s - loss: 1.6667 - mean_squared_error: 1.666 - ETA: 13s - loss: 1.6714 - mean_squared_error: 1.671 - ETA: 12s - loss: 1.6651 - mean_squared_error: 1.665 - ETA: 11s - loss: 1.6535 - mean_squared_error: 1.653 - ETA: 10s - loss: 1.6555 - mean_squared_error: 1.655 - ETA: 10s - loss: 1.6496 - mean_squared_error: 1.649 - ETA: 9s - loss: 1.6505 - mean_squared_error: 1.650 - ETA: 8s - loss: 1.6442 - mean_squared_error: 1.64 - ETA: 8s - loss: 1.6371 - mean_squared_error: 1.63 - ETA: 7s - loss: 1.6313 - mean_squared_error: 1.63 - ETA: 7s - loss: 1.6341 - mean_squared_error: 1.63 - ETA: 7s - loss: 1.6222 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6294 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6328 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6300 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6264 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6315 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6284 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6343 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6315 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6270 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6283 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6327 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6323 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6312 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6297 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6265 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6243 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6233 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6210 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6244 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6251 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6278 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6296 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6294 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6284 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6281 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6255 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6258 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6258 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6272 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6299 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6285 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6308 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6315 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6307 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6309 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6316 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6321 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6332 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6345 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6344 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6353 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6347 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6339 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6353 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6360 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6357 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6346 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6331 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6341 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6348 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6339 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6341 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6339 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6349 - mean_squared_error: 1.63 - 9s 2us/step - loss: 1.6347 - mean_squared_error: 1.6347\n",
      "Epoch 5/5\n",
      "3746814/3746814 [==============================] - ETA: 28s - loss: 1.6427 - mean_squared_error: 1.642 - ETA: 16s - loss: 1.6497 - mean_squared_error: 1.649 - ETA: 13s - loss: 1.6248 - mean_squared_error: 1.624 - ETA: 12s - loss: 1.6239 - mean_squared_error: 1.623 - ETA: 11s - loss: 1.6351 - mean_squared_error: 1.635 - ETA: 10s - loss: 1.6332 - mean_squared_error: 1.633 - ETA: 9s - loss: 1.6506 - mean_squared_error: 1.650 - ETA: 9s - loss: 1.6524 - mean_squared_error: 1.65 - ETA: 9s - loss: 1.6416 - mean_squared_error: 1.64 - ETA: 8s - loss: 1.6322 - mean_squared_error: 1.63 - ETA: 8s - loss: 1.6296 - mean_squared_error: 1.62 - ETA: 8s - loss: 1.6311 - mean_squared_error: 1.63 - ETA: 8s - loss: 1.6268 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6280 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6277 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6285 - mean_squared_error: 1.62 - ETA: 7s - loss: 1.6288 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6306 - mean_squared_error: 1.63 - ETA: 6s - loss: 1.6237 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6285 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6295 - mean_squared_error: 1.62 - ETA: 6s - loss: 1.6334 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6317 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6355 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6350 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6346 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6337 - mean_squared_error: 1.63 - ETA: 5s - loss: 1.6281 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6287 - mean_squared_error: 1.62 - ETA: 5s - loss: 1.6271 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6228 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6268 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6264 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6250 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6252 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6278 - mean_squared_error: 1.62 - ETA: 4s - loss: 1.6285 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6273 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6254 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6259 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6299 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6279 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6253 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6222 - mean_squared_error: 1.62 - ETA: 3s - loss: 1.6248 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6293 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6302 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6308 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6319 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6301 - mean_squared_error: 1.63 - ETA: 2s - loss: 1.6274 - mean_squared_error: 1.62 - ETA: 2s - loss: 1.6284 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6290 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6306 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6311 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6293 - mean_squared_error: 1.62 - ETA: 1s - loss: 1.6308 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6332 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6348 - mean_squared_error: 1.63 - ETA: 1s - loss: 1.6354 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6344 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6353 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6349 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6369 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6351 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6354 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6345 - mean_squared_error: 1.63 - ETA: 0s - loss: 1.6349 - mean_squared_error: 1.63 - 9s 2us/step - loss: 1.6347 - mean_squared_error: 1.6347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1bbce6ef0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221482/221482 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - 0s 1us/step\n",
      "lightgbm runs for 52.30 seconds.\n",
      "Total running time was 8.04 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                        | 1/8 [08:02<56:16, 482.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month28\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.974763\n",
      "Test RMSE for SGDRegressor is 0.901237\n",
      "SGDRegressor runs for 11.06 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.859644\n",
      "Test RMSE for lightgbm is 0.868869\n",
      "lightgbm runs for 415.68 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "3968296/3968296 [==============================] - ETA: 48s - loss: 1.4252 - mean_squared_error: 1.425 - ETA: 26s - loss: 1.4698 - mean_squared_error: 1.469 - ETA: 19s - loss: 1.5053 - mean_squared_error: 1.505 - ETA: 15s - loss: 1.4995 - mean_squared_error: 1.499 - ETA: 13s - loss: 1.4812 - mean_squared_error: 1.481 - ETA: 12s - loss: 1.4650 - mean_squared_error: 1.465 - ETA: 12s - loss: 1.4656 - mean_squared_error: 1.465 - ETA: 11s - loss: 1.4600 - mean_squared_error: 1.460 - ETA: 10s - loss: 1.4598 - mean_squared_error: 1.459 - ETA: 10s - loss: 1.4629 - mean_squared_error: 1.462 - ETA: 9s - loss: 1.4618 - mean_squared_error: 1.461 - ETA: 9s - loss: 1.4644 - mean_squared_error: 1.46 - ETA: 9s - loss: 1.4631 - mean_squared_error: 1.46 - ETA: 8s - loss: 1.4536 - mean_squared_error: 1.45 - ETA: 8s - loss: 1.4493 - mean_squared_error: 1.44 - ETA: 7s - loss: 1.4500 - mean_squared_error: 1.45 - ETA: 7s - loss: 1.4411 - mean_squared_error: 1.44 - ETA: 7s - loss: 1.4383 - mean_squared_error: 1.43 - ETA: 7s - loss: 1.4285 - mean_squared_error: 1.42 - ETA: 7s - loss: 1.4258 - mean_squared_error: 1.42 - ETA: 7s - loss: 1.4222 - mean_squared_error: 1.42 - ETA: 6s - loss: 1.4174 - mean_squared_error: 1.41 - ETA: 6s - loss: 1.4113 - mean_squared_error: 1.41 - ETA: 6s - loss: 1.4055 - mean_squared_error: 1.40 - ETA: 6s - loss: 1.4010 - mean_squared_error: 1.40 - ETA: 6s - loss: 1.3970 - mean_squared_error: 1.39 - ETA: 6s - loss: 1.3918 - mean_squared_error: 1.39 - ETA: 5s - loss: 1.3811 - mean_squared_error: 1.38 - ETA: 5s - loss: 1.3749 - mean_squared_error: 1.37 - ETA: 5s - loss: 1.3704 - mean_squared_error: 1.37 - ETA: 5s - loss: 1.3622 - mean_squared_error: 1.36 - ETA: 5s - loss: 1.3566 - mean_squared_error: 1.35 - ETA: 5s - loss: 1.3475 - mean_squared_error: 1.34 - ETA: 4s - loss: 1.3433 - mean_squared_error: 1.34 - ETA: 4s - loss: 1.3365 - mean_squared_error: 1.33 - ETA: 4s - loss: 1.3327 - mean_squared_error: 1.33 - ETA: 4s - loss: 1.3305 - mean_squared_error: 1.33 - ETA: 4s - loss: 1.3239 - mean_squared_error: 1.32 - ETA: 4s - loss: 1.3193 - mean_squared_error: 1.31 - ETA: 4s - loss: 1.3143 - mean_squared_error: 1.31 - ETA: 4s - loss: 1.3098 - mean_squared_error: 1.30 - ETA: 3s - loss: 1.3061 - mean_squared_error: 1.30 - ETA: 3s - loss: 1.3020 - mean_squared_error: 1.30 - ETA: 3s - loss: 1.2977 - mean_squared_error: 1.29 - ETA: 3s - loss: 1.2922 - mean_squared_error: 1.29 - ETA: 3s - loss: 1.2858 - mean_squared_error: 1.28 - ETA: 3s - loss: 1.2799 - mean_squared_error: 1.27 - ETA: 3s - loss: 1.2767 - mean_squared_error: 1.27 - ETA: 2s - loss: 1.2736 - mean_squared_error: 1.27 - ETA: 2s - loss: 1.2680 - mean_squared_error: 1.26 - ETA: 2s - loss: 1.2633 - mean_squared_error: 1.26 - ETA: 2s - loss: 1.2580 - mean_squared_error: 1.25 - ETA: 2s - loss: 1.2537 - mean_squared_error: 1.25 - ETA: 2s - loss: 1.2497 - mean_squared_error: 1.24 - ETA: 2s - loss: 1.2464 - mean_squared_error: 1.24 - ETA: 2s - loss: 1.2433 - mean_squared_error: 1.24 - ETA: 1s - loss: 1.2382 - mean_squared_error: 1.23 - ETA: 1s - loss: 1.2338 - mean_squared_error: 1.23 - ETA: 1s - loss: 1.2314 - mean_squared_error: 1.23 - ETA: 1s - loss: 1.2292 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2259 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2229 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2205 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2172 - mean_squared_error: 1.21 - ETA: 0s - loss: 1.2145 - mean_squared_error: 1.21 - ETA: 0s - loss: 1.2126 - mean_squared_error: 1.21 - ETA: 0s - loss: 1.2097 - mean_squared_error: 1.20 - ETA: 0s - loss: 1.2062 - mean_squared_error: 1.20 - ETA: 0s - loss: 1.2021 - mean_squared_error: 1.20 - ETA: 0s - loss: 1.1995 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1960 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1932 - mean_squared_error: 1.19 - 9s 2us/step - loss: 1.1931 - mean_squared_error: 1.1931\n",
      "Epoch 2/5\n",
      "3968296/3968296 [==============================] - ETA: 27s - loss: 1.0252 - mean_squared_error: 1.025 - ETA: 17s - loss: 1.0000 - mean_squared_error: 1.000 - ETA: 13s - loss: 1.0098 - mean_squared_error: 1.009 - ETA: 11s - loss: 0.9858 - mean_squared_error: 0.985 - ETA: 10s - loss: 0.9775 - mean_squared_error: 0.977 - ETA: 9s - loss: 0.9743 - mean_squared_error: 0.974 - ETA: 8s - loss: 0.9746 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9664 - mean_squared_error: 0.96 - ETA: 8s - loss: 0.9715 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9714 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9741 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9796 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9735 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9675 - mean_squared_error: 0.96 - ETA: 7s - loss: 0.9642 - mean_squared_error: 0.96 - ETA: 7s - loss: 0.9606 - mean_squared_error: 0.96 - ETA: 6s - loss: 0.9617 - mean_squared_error: 0.96 - ETA: 6s - loss: 0.9600 - mean_squared_error: 0.96 - ETA: 6s - loss: 0.9598 - mean_squared_error: 0.95 - ETA: 6s - loss: 0.9591 - mean_squared_error: 0.95 - ETA: 6s - loss: 0.9595 - mean_squared_error: 0.95 - ETA: 5s - loss: 0.9578 - mean_squared_error: 0.95 - ETA: 5s - loss: 0.9609 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9657 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9675 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9678 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9705 - mean_squared_error: 0.97 - ETA: 5s - loss: 0.9661 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9646 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9617 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9601 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9601 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9607 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9606 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9604 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9626 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9613 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9601 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9609 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9596 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9593 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9574 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9550 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9521 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9521 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9510 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9500 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9495 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9497 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9502 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9490 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9495 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9488 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9478 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9463 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9451 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9451 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9458 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9472 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9487 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9487 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9477 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9468 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9465 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9454 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9449 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9451 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9442 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9445 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9443 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9438 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9442 - mean_squared_error: 0.94 - 8s 2us/step - loss: 0.9441 - mean_squared_error: 0.9441\n",
      "Epoch 3/5\n",
      "3968296/3968296 [==============================] - ETA: 23s - loss: 0.8860 - mean_squared_error: 0.886 - ETA: 14s - loss: 0.8845 - mean_squared_error: 0.884 - ETA: 10s - loss: 0.8999 - mean_squared_error: 0.899 - ETA: 9s - loss: 0.9022 - mean_squared_error: 0.902 - ETA: 8s - loss: 0.9137 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9156 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9139 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9156 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9187 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9220 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9201 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9165 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9121 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9110 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9067 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9038 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9075 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9118 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9119 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9116 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9139 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9159 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9142 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9161 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9159 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9188 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9187 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9189 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9178 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9154 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9140 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9167 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9177 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9180 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9182 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9193 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9199 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9194 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9182 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9182 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9186 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9190 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9189 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9181 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9173 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9183 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9168 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9162 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9161 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9166 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9182 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9179 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9189 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9183 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9175 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9180 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9173 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9166 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9176 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9184 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9187 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9188 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9180 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9178 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9177 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9162 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9163 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9174 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9178 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9181 - mean_squared_error: 0.91 - 9s 2us/step - loss: 0.9186 - mean_squared_error: 0.9186\n",
      "Epoch 4/5\n",
      "3968296/3968296 [==============================] - ETA: 31s - loss: 0.9094 - mean_squared_error: 0.909 - ETA: 18s - loss: 0.9255 - mean_squared_error: 0.925 - ETA: 14s - loss: 0.9383 - mean_squared_error: 0.938 - ETA: 12s - loss: 0.9219 - mean_squared_error: 0.921 - ETA: 10s - loss: 0.9113 - mean_squared_error: 0.911 - ETA: 10s - loss: 0.9116 - mean_squared_error: 0.911 - ETA: 9s - loss: 0.9139 - mean_squared_error: 0.913 - ETA: 9s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 9s - loss: 0.9050 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9083 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9023 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9048 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9091 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9041 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9041 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9060 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9056 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9046 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9063 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9019 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9055 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9052 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9032 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9032 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9025 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9023 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9051 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9079 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9086 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9071 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9069 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9067 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9063 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9064 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9080 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9077 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9106 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9107 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9098 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9092 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9108 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9115 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9125 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9116 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9128 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9161 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9149 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9152 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9151 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9157 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9154 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9143 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9143 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9148 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9157 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9159 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9166 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9160 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9162 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9152 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9154 - mean_squared_error: 0.91 - 9s 2us/step - loss: 0.9150 - mean_squared_error: 0.9150\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3968296/3968296 [==============================] - ETA: 29s - loss: 0.9777 - mean_squared_error: 0.977 - ETA: 18s - loss: 0.9379 - mean_squared_error: 0.937 - ETA: 14s - loss: 0.9497 - mean_squared_error: 0.949 - ETA: 12s - loss: 0.9449 - mean_squared_error: 0.944 - ETA: 11s - loss: 0.9382 - mean_squared_error: 0.938 - ETA: 11s - loss: 0.9164 - mean_squared_error: 0.916 - ETA: 10s - loss: 0.9185 - mean_squared_error: 0.918 - ETA: 10s - loss: 0.9163 - mean_squared_error: 0.916 - ETA: 9s - loss: 0.9164 - mean_squared_error: 0.916 - ETA: 9s - loss: 0.9077 - mean_squared_error: 0.90 - ETA: 9s - loss: 0.8995 - mean_squared_error: 0.89 - ETA: 8s - loss: 0.9014 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9044 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9087 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9087 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9084 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9083 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9038 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.9027 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.8991 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8980 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.9006 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9014 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9012 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9018 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9012 - mean_squared_error: 0.90 - ETA: 6s - loss: 0.9022 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9009 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.8999 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.9006 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.8995 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.9014 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9021 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9008 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9021 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9016 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9025 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9007 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9011 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9029 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9047 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9052 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9061 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9069 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9099 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9118 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9122 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9133 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9126 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9135 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9143 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9150 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9134 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9134 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9134 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9140 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9136 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9130 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9125 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9119 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9122 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9123 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9114 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9115 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9126 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9132 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9130 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9132 - mean_squared_error: 0.91 - 8s 2us/step - loss: 0.9130 - mean_squared_error: 0.9130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e18259b2e8>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212503/212503 [==============================] - ETA:  - ETA:  - 0s 1us/step\n",
      "lightgbm runs for 44.59 seconds.\n",
      "Total running time was 7.88 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                              | 2/8 [15:55<47:57, 479.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month29\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.971967\n",
      "Test RMSE for SGDRegressor is 0.825820\n",
      "SGDRegressor runs for 12.17 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.855837\n",
      "Test RMSE for lightgbm is 0.805780\n",
      "lightgbm runs for 324.87 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "4180799/4180799 [==============================] - ETA: 18s - loss: 1.5848 - mean_squared_error: 1.584 - ETA: 7s - loss: 1.6055 - mean_squared_error: 1.605 - ETA: 5s - loss: 1.5771 - mean_squared_error: 1.57 - ETA: 4s - loss: 1.5631 - mean_squared_error: 1.56 - ETA: 3s - loss: 1.5555 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5477 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5319 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5139 - mean_squared_error: 1.51 - ETA: 2s - loss: 1.5034 - mean_squared_error: 1.50 - ETA: 2s - loss: 1.4936 - mean_squared_error: 1.49 - ETA: 2s - loss: 1.4905 - mean_squared_error: 1.49 - ETA: 1s - loss: 1.4793 - mean_squared_error: 1.47 - ETA: 1s - loss: 1.4674 - mean_squared_error: 1.46 - ETA: 1s - loss: 1.4647 - mean_squared_error: 1.46 - ETA: 1s - loss: 1.4524 - mean_squared_error: 1.45 - ETA: 1s - loss: 1.4465 - mean_squared_error: 1.44 - ETA: 1s - loss: 1.4402 - mean_squared_error: 1.44 - ETA: 1s - loss: 1.4336 - mean_squared_error: 1.43 - ETA: 1s - loss: 1.4247 - mean_squared_error: 1.42 - ETA: 1s - loss: 1.4177 - mean_squared_error: 1.41 - ETA: 1s - loss: 1.4071 - mean_squared_error: 1.40 - ETA: 1s - loss: 1.3967 - mean_squared_error: 1.39 - ETA: 1s - loss: 1.3881 - mean_squared_error: 1.38 - ETA: 0s - loss: 1.3764 - mean_squared_error: 1.37 - ETA: 0s - loss: 1.3670 - mean_squared_error: 1.36 - ETA: 0s - loss: 1.3592 - mean_squared_error: 1.35 - ETA: 0s - loss: 1.3486 - mean_squared_error: 1.34 - ETA: 0s - loss: 1.3421 - mean_squared_error: 1.34 - ETA: 0s - loss: 1.3316 - mean_squared_error: 1.33 - ETA: 0s - loss: 1.3233 - mean_squared_error: 1.32 - ETA: 0s - loss: 1.3154 - mean_squared_error: 1.31 - ETA: 0s - loss: 1.3062 - mean_squared_error: 1.30 - ETA: 0s - loss: 1.2992 - mean_squared_error: 1.29 - ETA: 0s - loss: 1.2910 - mean_squared_error: 1.29 - ETA: 0s - loss: 1.2839 - mean_squared_error: 1.28 - ETA: 0s - loss: 1.2768 - mean_squared_error: 1.27 - ETA: 0s - loss: 1.2693 - mean_squared_error: 1.26 - ETA: 0s - loss: 1.2622 - mean_squared_error: 1.26 - 2s 1us/step - loss: 1.2595 - mean_squared_error: 1.2595\n",
      "Epoch 2/5\n",
      "4180799/4180799 [==============================] - ETA: 9s - loss: 0.8978 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.9886 - mean_squared_error: 0.98 - ETA: 3s - loss: 0.9834 - mean_squared_error: 0.98 - ETA: 2s - loss: 0.9708 - mean_squared_error: 0.97 - ETA: 2s - loss: 0.9869 - mean_squared_error: 0.98 - ETA: 2s - loss: 0.9844 - mean_squared_error: 0.98 - ETA: 2s - loss: 0.9801 - mean_squared_error: 0.98 - ETA: 2s - loss: 0.9716 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9760 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9782 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9779 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9809 - mean_squared_error: 0.98 - ETA: 1s - loss: 0.9752 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9693 - mean_squared_error: 0.96 - ETA: 1s - loss: 0.9724 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9738 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9736 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9734 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9731 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9722 - mean_squared_error: 0.97 - ETA: 1s - loss: 0.9720 - mean_squared_error: 0.97 - ETA: 0s - loss: 0.9696 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9679 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9655 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9639 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9647 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9637 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9632 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9631 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9614 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9610 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9614 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9601 - mean_squared_error: 0.96 - ETA: 0s - loss: 0.9591 - mean_squared_error: 0.95 - ETA: 0s - loss: 0.9585 - mean_squared_error: 0.95 - ETA: 0s - loss: 0.9568 - mean_squared_error: 0.95 - ETA: 0s - loss: 0.9571 - mean_squared_error: 0.95 - ETA: 0s - loss: 0.9565 - mean_squared_error: 0.95 - 2s 1us/step - loss: 0.9563 - mean_squared_error: 0.9563\n",
      "Epoch 3/5\n",
      "4180799/4180799 [==============================] - ETA: 9s - loss: 0.8792 - mean_squared_error: 0.87 - ETA: 4s - loss: 0.9094 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.8971 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8891 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.9036 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.9126 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9137 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9208 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9168 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9174 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9160 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9177 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9133 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9133 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9122 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9114 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9103 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9116 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9133 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9135 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9132 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9138 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9136 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9132 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9175 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9171 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9156 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9151 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9156 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9163 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9157 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9166 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9177 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9177 - mean_squared_error: 0.91 - 2s 1us/step - loss: 0.9176 - mean_squared_error: 0.9176\n",
      "Epoch 4/5\n",
      "4180799/4180799 [==============================] - ETA: 9s - loss: 0.9877 - mean_squared_error: 0.98 - ETA: 4s - loss: 0.9421 - mean_squared_error: 0.94 - ETA: 3s - loss: 0.9441 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9283 - mean_squared_error: 0.92 - ETA: 2s - loss: 0.9376 - mean_squared_error: 0.93 - ETA: 2s - loss: 0.9421 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9428 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9435 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9420 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9372 - mean_squared_error: 0.93 - ETA: 1s - loss: 0.9388 - mean_squared_error: 0.93 - ETA: 1s - loss: 0.9310 - mean_squared_error: 0.93 - ETA: 1s - loss: 0.9306 - mean_squared_error: 0.93 - ETA: 1s - loss: 0.9290 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9270 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9247 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9212 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9205 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9200 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9209 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9185 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9195 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9201 - mean_squared_error: 0.92 - ETA: 0s - loss: 0.9193 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9177 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9174 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9163 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9128 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9145 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9131 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9126 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9123 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9117 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9123 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9122 - mean_squared_error: 0.91 - 2s 1us/step - loss: 0.9118 - mean_squared_error: 0.9118\n",
      "Epoch 5/5\n",
      "4180799/4180799 [==============================] - ETA: 9s - loss: 0.9119 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9398 - mean_squared_error: 0.93 - ETA: 3s - loss: 0.9341 - mean_squared_error: 0.93 - ETA: 2s - loss: 0.9186 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9136 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9124 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9104 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9108 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9061 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9057 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9055 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9051 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9091 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9111 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9080 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9076 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9058 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9076 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9068 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9072 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9081 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9071 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9088 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9098 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9099 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9106 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9094 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9094 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9102 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9099 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9099 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9097 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9113 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9099 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9103 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9099 - mean_squared_error: 0.90 - 2s 1us/step - loss: 0.9093 - mean_squared_error: 0.9093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e188898438>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210494/210494 [==============================] - ETA:  - 0s 0us/step\n",
      "lightgbm runs for 11.37 seconds.\n",
      "Total running time was 5.83 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                   | 3/8 [21:45<36:43, 440.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month30\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.967234\n",
      "Test RMSE for SGDRegressor is 0.758693\n",
      "SGDRegressor runs for 4.44 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.852244\n",
      "Test RMSE for lightgbm is 0.730400\n",
      "lightgbm runs for 341.95 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "4391293/4391293 [==============================] - ETA: 1:04 - loss: 1.5921 - mean_squared_error: 1.59 - ETA: 36s - loss: 1.6460 - mean_squared_error: 1.6460 - ETA: 27s - loss: 1.6039 - mean_squared_error: 1.603 - ETA: 22s - loss: 1.6004 - mean_squared_error: 1.600 - ETA: 19s - loss: 1.5736 - mean_squared_error: 1.573 - ETA: 17s - loss: 1.5544 - mean_squared_error: 1.554 - ETA: 16s - loss: 1.5394 - mean_squared_error: 1.539 - ETA: 15s - loss: 1.5211 - mean_squared_error: 1.521 - ETA: 14s - loss: 1.5135 - mean_squared_error: 1.513 - ETA: 13s - loss: 1.5224 - mean_squared_error: 1.522 - ETA: 12s - loss: 1.5154 - mean_squared_error: 1.515 - ETA: 12s - loss: 1.5132 - mean_squared_error: 1.513 - ETA: 11s - loss: 1.5145 - mean_squared_error: 1.514 - ETA: 11s - loss: 1.5040 - mean_squared_error: 1.504 - ETA: 10s - loss: 1.4946 - mean_squared_error: 1.494 - ETA: 10s - loss: 1.4928 - mean_squared_error: 1.492 - ETA: 10s - loss: 1.4902 - mean_squared_error: 1.490 - ETA: 9s - loss: 1.4874 - mean_squared_error: 1.487 - ETA: 9s - loss: 1.4850 - mean_squared_error: 1.48 - ETA: 9s - loss: 1.4791 - mean_squared_error: 1.47 - ETA: 9s - loss: 1.4765 - mean_squared_error: 1.47 - ETA: 8s - loss: 1.4762 - mean_squared_error: 1.47 - ETA: 8s - loss: 1.4733 - mean_squared_error: 1.47 - ETA: 8s - loss: 1.4692 - mean_squared_error: 1.46 - ETA: 8s - loss: 1.4709 - mean_squared_error: 1.47 - ETA: 8s - loss: 1.4686 - mean_squared_error: 1.46 - ETA: 7s - loss: 1.4670 - mean_squared_error: 1.46 - ETA: 7s - loss: 1.4572 - mean_squared_error: 1.45 - ETA: 7s - loss: 1.4553 - mean_squared_error: 1.45 - ETA: 7s - loss: 1.4467 - mean_squared_error: 1.44 - ETA: 7s - loss: 1.4433 - mean_squared_error: 1.44 - ETA: 6s - loss: 1.4416 - mean_squared_error: 1.44 - ETA: 6s - loss: 1.4379 - mean_squared_error: 1.43 - ETA: 6s - loss: 1.4349 - mean_squared_error: 1.43 - ETA: 6s - loss: 1.4279 - mean_squared_error: 1.42 - ETA: 5s - loss: 1.4233 - mean_squared_error: 1.42 - ETA: 5s - loss: 1.4164 - mean_squared_error: 1.41 - ETA: 5s - loss: 1.4116 - mean_squared_error: 1.41 - ETA: 5s - loss: 1.4094 - mean_squared_error: 1.40 - ETA: 5s - loss: 1.4058 - mean_squared_error: 1.40 - ETA: 5s - loss: 1.4010 - mean_squared_error: 1.40 - ETA: 4s - loss: 1.3954 - mean_squared_error: 1.39 - ETA: 4s - loss: 1.3902 - mean_squared_error: 1.39 - ETA: 4s - loss: 1.3857 - mean_squared_error: 1.38 - ETA: 4s - loss: 1.3799 - mean_squared_error: 1.37 - ETA: 4s - loss: 1.3743 - mean_squared_error: 1.37 - ETA: 4s - loss: 1.3693 - mean_squared_error: 1.36 - ETA: 4s - loss: 1.3659 - mean_squared_error: 1.36 - ETA: 3s - loss: 1.3602 - mean_squared_error: 1.36 - ETA: 3s - loss: 1.3541 - mean_squared_error: 1.35 - ETA: 3s - loss: 1.3480 - mean_squared_error: 1.34 - ETA: 3s - loss: 1.3431 - mean_squared_error: 1.34 - ETA: 3s - loss: 1.3394 - mean_squared_error: 1.33 - ETA: 3s - loss: 1.3344 - mean_squared_error: 1.33 - ETA: 3s - loss: 1.3304 - mean_squared_error: 1.33 - ETA: 3s - loss: 1.3265 - mean_squared_error: 1.32 - ETA: 2s - loss: 1.3221 - mean_squared_error: 1.32 - ETA: 2s - loss: 1.3181 - mean_squared_error: 1.31 - ETA: 2s - loss: 1.3156 - mean_squared_error: 1.31 - ETA: 2s - loss: 1.3122 - mean_squared_error: 1.31 - ETA: 2s - loss: 1.3075 - mean_squared_error: 1.30 - ETA: 2s - loss: 1.3035 - mean_squared_error: 1.30 - ETA: 2s - loss: 1.3002 - mean_squared_error: 1.30 - ETA: 2s - loss: 1.2948 - mean_squared_error: 1.29 - ETA: 1s - loss: 1.2901 - mean_squared_error: 1.29 - ETA: 1s - loss: 1.2862 - mean_squared_error: 1.28 - ETA: 1s - loss: 1.2818 - mean_squared_error: 1.28 - ETA: 1s - loss: 1.2778 - mean_squared_error: 1.27 - ETA: 1s - loss: 1.2738 - mean_squared_error: 1.27 - ETA: 1s - loss: 1.2696 - mean_squared_error: 1.26 - ETA: 1s - loss: 1.2664 - mean_squared_error: 1.26 - ETA: 0s - loss: 1.2629 - mean_squared_error: 1.26 - ETA: 0s - loss: 1.2589 - mean_squared_error: 1.25 - ETA: 0s - loss: 1.2561 - mean_squared_error: 1.25 - ETA: 0s - loss: 1.2531 - mean_squared_error: 1.25 - ETA: 0s - loss: 1.2490 - mean_squared_error: 1.24 - ETA: 0s - loss: 1.2449 - mean_squared_error: 1.24 - ETA: 0s - loss: 1.2418 - mean_squared_error: 1.24 - ETA: 0s - loss: 1.2384 - mean_squared_error: 1.23 - 10s 2us/step - loss: 1.2357 - mean_squared_error: 1.2357\n",
      "Epoch 2/5\n",
      "4391293/4391293 [==============================] - ETA: 36s - loss: 1.0323 - mean_squared_error: 1.032 - ETA: 22s - loss: 0.9909 - mean_squared_error: 0.990 - ETA: 17s - loss: 0.9840 - mean_squared_error: 0.984 - ETA: 15s - loss: 0.9726 - mean_squared_error: 0.972 - ETA: 14s - loss: 0.9687 - mean_squared_error: 0.968 - ETA: 13s - loss: 0.9689 - mean_squared_error: 0.968 - ETA: 12s - loss: 0.9817 - mean_squared_error: 0.981 - ETA: 11s - loss: 0.9780 - mean_squared_error: 0.978 - ETA: 11s - loss: 0.9808 - mean_squared_error: 0.980 - ETA: 10s - loss: 0.9859 - mean_squared_error: 0.985 - ETA: 10s - loss: 0.9867 - mean_squared_error: 0.986 - ETA: 10s - loss: 0.9762 - mean_squared_error: 0.976 - ETA: 10s - loss: 0.9746 - mean_squared_error: 0.974 - ETA: 9s - loss: 0.9744 - mean_squared_error: 0.974 - ETA: 9s - loss: 0.9761 - mean_squared_error: 0.97 - ETA: 9s - loss: 0.9767 - mean_squared_error: 0.97 - ETA: 9s - loss: 0.9738 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9763 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9784 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9739 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9753 - mean_squared_error: 0.97 - ETA: 8s - loss: 0.9756 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9741 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9732 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9712 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9709 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9714 - mean_squared_error: 0.97 - ETA: 7s - loss: 0.9728 - mean_squared_error: 0.97 - ETA: 6s - loss: 0.9726 - mean_squared_error: 0.97 - ETA: 6s - loss: 0.9730 - mean_squared_error: 0.97 - ETA: 6s - loss: 0.9705 - mean_squared_error: 0.97 - ETA: 6s - loss: 0.9731 - mean_squared_error: 0.97 - ETA: 6s - loss: 0.9732 - mean_squared_error: 0.97 - ETA: 5s - loss: 0.9715 - mean_squared_error: 0.97 - ETA: 5s - loss: 0.9707 - mean_squared_error: 0.97 - ETA: 5s - loss: 0.9690 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9669 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9669 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9673 - mean_squared_error: 0.96 - ETA: 5s - loss: 0.9681 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9674 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9667 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9664 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9658 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9653 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9643 - mean_squared_error: 0.96 - ETA: 4s - loss: 0.9645 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9633 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9625 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9623 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9608 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9596 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9581 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9586 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9585 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9579 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9573 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9568 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9544 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9539 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9533 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9537 - mean_squared_error: 0.95 - ETA: 2s - loss: 0.9533 - mean_squared_error: 0.95 - ETA: 1s - loss: 0.9535 - mean_squared_error: 0.95 - ETA: 1s - loss: 0.9525 - mean_squared_error: 0.95 - ETA: 1s - loss: 0.9521 - mean_squared_error: 0.95 - ETA: 1s - loss: 0.9494 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9496 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9488 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9483 - mean_squared_error: 0.94 - ETA: 1s - loss: 0.9479 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9476 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9462 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9452 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9439 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9429 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9436 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9433 - mean_squared_error: 0.94 - ETA: 0s - loss: 0.9428 - mean_squared_error: 0.94 - 10s 2us/step - loss: 0.9420 - mean_squared_error: 0.9420\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4391293/4391293 [==============================] - ETA: 35s - loss: 0.9071 - mean_squared_error: 0.907 - ETA: 21s - loss: 0.8838 - mean_squared_error: 0.883 - ETA: 16s - loss: 0.8953 - mean_squared_error: 0.895 - ETA: 13s - loss: 0.8914 - mean_squared_error: 0.891 - ETA: 12s - loss: 0.8979 - mean_squared_error: 0.897 - ETA: 11s - loss: 0.9098 - mean_squared_error: 0.909 - ETA: 10s - loss: 0.9165 - mean_squared_error: 0.916 - ETA: 9s - loss: 0.9183 - mean_squared_error: 0.918 - ETA: 9s - loss: 0.9088 - mean_squared_error: 0.90 - ETA: 9s - loss: 0.9140 - mean_squared_error: 0.91 - ETA: 9s - loss: 0.9155 - mean_squared_error: 0.91 - ETA: 9s - loss: 0.9145 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9121 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9170 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9151 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9102 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9127 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9138 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9165 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9168 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9189 - mean_squared_error: 0.91 - ETA: 7s - loss: 0.9221 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9254 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9235 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9195 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9205 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9197 - mean_squared_error: 0.91 - ETA: 6s - loss: 0.9205 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9193 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9193 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9203 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9176 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9169 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 5s - loss: 0.9175 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9173 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9170 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9152 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9161 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9154 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9157 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9150 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9154 - mean_squared_error: 0.91 - ETA: 4s - loss: 0.9145 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9134 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9131 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9129 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9132 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9145 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9135 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9139 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9127 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9115 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9115 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9124 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9125 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9124 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9101 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9101 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9094 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9097 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9082 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9084 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9084 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9082 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9085 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9076 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9074 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9071 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9071 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9059 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9055 - mean_squared_error: 0.90 - 10s 2us/step - loss: 0.9056 - mean_squared_error: 0.9056\n",
      "Epoch 4/5\n",
      "4391293/4391293 [==============================] - ETA: 34s - loss: 0.9167 - mean_squared_error: 0.916 - ETA: 20s - loss: 0.8842 - mean_squared_error: 0.884 - ETA: 15s - loss: 0.8985 - mean_squared_error: 0.898 - ETA: 14s - loss: 0.8946 - mean_squared_error: 0.894 - ETA: 12s - loss: 0.8887 - mean_squared_error: 0.888 - ETA: 12s - loss: 0.8944 - mean_squared_error: 0.894 - ETA: 11s - loss: 0.8874 - mean_squared_error: 0.887 - ETA: 11s - loss: 0.8824 - mean_squared_error: 0.882 - ETA: 10s - loss: 0.8757 - mean_squared_error: 0.875 - ETA: 10s - loss: 0.8804 - mean_squared_error: 0.880 - ETA: 10s - loss: 0.8715 - mean_squared_error: 0.871 - ETA: 9s - loss: 0.8715 - mean_squared_error: 0.871 - ETA: 9s - loss: 0.8725 - mean_squared_error: 0.87 - ETA: 9s - loss: 0.8751 - mean_squared_error: 0.87 - ETA: 9s - loss: 0.8822 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8849 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8813 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8841 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8824 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8817 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8801 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8813 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8828 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8841 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8875 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8875 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8907 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8913 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8899 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8898 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8925 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8935 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8913 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8931 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8927 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8937 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8939 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8951 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8942 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8940 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8951 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8953 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8952 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8968 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8981 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8969 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8977 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8972 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8976 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8975 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8995 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8989 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8996 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8993 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8996 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.9008 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.9007 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.9001 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.8995 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8993 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8982 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8984 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8987 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8995 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8994 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.9002 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9000 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.8993 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.9002 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9016 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9010 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9001 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9004 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9004 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9004 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.8994 - mean_squared_error: 0.89 - 10s 2us/step - loss: 0.9000 - mean_squared_error: 0.9000\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4391293/4391293 [==============================] - ETA: 35s - loss: 0.8889 - mean_squared_error: 0.888 - ETA: 21s - loss: 0.8722 - mean_squared_error: 0.872 - ETA: 15s - loss: 0.9008 - mean_squared_error: 0.900 - ETA: 14s - loss: 0.9191 - mean_squared_error: 0.919 - ETA: 12s - loss: 0.9252 - mean_squared_error: 0.925 - ETA: 12s - loss: 0.9336 - mean_squared_error: 0.933 - ETA: 11s - loss: 0.9274 - mean_squared_error: 0.927 - ETA: 11s - loss: 0.9317 - mean_squared_error: 0.931 - ETA: 10s - loss: 0.9183 - mean_squared_error: 0.918 - ETA: 10s - loss: 0.9132 - mean_squared_error: 0.913 - ETA: 10s - loss: 0.9141 - mean_squared_error: 0.914 - ETA: 9s - loss: 0.9160 - mean_squared_error: 0.916 - ETA: 9s - loss: 0.9092 - mean_squared_error: 0.90 - ETA: 9s - loss: 0.9069 - mean_squared_error: 0.90 - ETA: 9s - loss: 0.9102 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 8s - loss: 0.9044 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9048 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9029 - mean_squared_error: 0.90 - ETA: 8s - loss: 0.9042 - mean_squared_error: 0.90 - ETA: 7s - loss: 0.8987 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8979 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8947 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8946 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8951 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8952 - mean_squared_error: 0.89 - ETA: 7s - loss: 0.8944 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8921 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8956 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8935 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8936 - mean_squared_error: 0.89 - ETA: 6s - loss: 0.8940 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8961 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8982 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.8992 - mean_squared_error: 0.89 - ETA: 5s - loss: 0.9010 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9022 - mean_squared_error: 0.90 - ETA: 5s - loss: 0.9003 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9023 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9014 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9006 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9015 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.8996 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.9005 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.9013 - mean_squared_error: 0.90 - ETA: 4s - loss: 0.8997 - mean_squared_error: 0.89 - ETA: 4s - loss: 0.8999 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8988 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8990 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.9016 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.9010 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.8986 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8982 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8998 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.8997 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8992 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.9001 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.9005 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.9002 - mean_squared_error: 0.90 - ETA: 2s - loss: 0.8997 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8987 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8979 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8977 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8966 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8966 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8958 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8960 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8955 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8962 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8952 - mean_squared_error: 0.89 - ETA: 1s - loss: 0.8948 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8952 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8957 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8962 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8975 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8981 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8983 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8983 - mean_squared_error: 0.89 - ETA: 0s - loss: 0.8973 - mean_squared_error: 0.89 - 10s 2us/step - loss: 0.8973 - mean_squared_error: 0.8973\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e188dabf60>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215496/215496 [==============================] - ETA:  - ETA:  - ETA:  - 0s 2us/step\n",
      "lightgbm runs for 49.86 seconds.\n",
      "Total running time was 6.61 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                         | 4/8 [28:21<28:29, 427.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month31\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.949632\n",
      "Test RMSE for SGDRegressor is 0.833529\n",
      "SGDRegressor runs for 10.48 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.844984\n",
      "Test RMSE for lightgbm is 0.803555\n",
      "lightgbm runs for 454.64 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "4606789/4606789 [==============================] - ETA: 1:30 - loss: 1.5138 - mean_squared_error: 1.51 - ETA: 48s - loss: 1.4844 - mean_squared_error: 1.4844 - ETA: 34s - loss: 1.4617 - mean_squared_error: 1.461 - ETA: 27s - loss: 1.4538 - mean_squared_error: 1.453 - ETA: 23s - loss: 1.4420 - mean_squared_error: 1.442 - ETA: 21s - loss: 1.4618 - mean_squared_error: 1.461 - ETA: 19s - loss: 1.4482 - mean_squared_error: 1.448 - ETA: 17s - loss: 1.4404 - mean_squared_error: 1.440 - ETA: 16s - loss: 1.4414 - mean_squared_error: 1.441 - ETA: 15s - loss: 1.4361 - mean_squared_error: 1.436 - ETA: 14s - loss: 1.4396 - mean_squared_error: 1.439 - ETA: 14s - loss: 1.4394 - mean_squared_error: 1.439 - ETA: 13s - loss: 1.4405 - mean_squared_error: 1.440 - ETA: 13s - loss: 1.4460 - mean_squared_error: 1.446 - ETA: 12s - loss: 1.4402 - mean_squared_error: 1.440 - ETA: 12s - loss: 1.4399 - mean_squared_error: 1.439 - ETA: 11s - loss: 1.4449 - mean_squared_error: 1.444 - ETA: 11s - loss: 1.4365 - mean_squared_error: 1.436 - ETA: 11s - loss: 1.4322 - mean_squared_error: 1.432 - ETA: 10s - loss: 1.4346 - mean_squared_error: 1.434 - ETA: 10s - loss: 1.4325 - mean_squared_error: 1.432 - ETA: 9s - loss: 1.4335 - mean_squared_error: 1.433 - ETA: 9s - loss: 1.4284 - mean_squared_error: 1.42 - ETA: 9s - loss: 1.4220 - mean_squared_error: 1.42 - ETA: 8s - loss: 1.4174 - mean_squared_error: 1.41 - ETA: 8s - loss: 1.4117 - mean_squared_error: 1.41 - ETA: 8s - loss: 1.4118 - mean_squared_error: 1.41 - ETA: 8s - loss: 1.4059 - mean_squared_error: 1.40 - ETA: 7s - loss: 1.4042 - mean_squared_error: 1.40 - ETA: 7s - loss: 1.3997 - mean_squared_error: 1.39 - ETA: 7s - loss: 1.3964 - mean_squared_error: 1.39 - ETA: 7s - loss: 1.3903 - mean_squared_error: 1.39 - ETA: 7s - loss: 1.3870 - mean_squared_error: 1.38 - ETA: 7s - loss: 1.3818 - mean_squared_error: 1.38 - ETA: 6s - loss: 1.3782 - mean_squared_error: 1.37 - ETA: 6s - loss: 1.3733 - mean_squared_error: 1.37 - ETA: 6s - loss: 1.3673 - mean_squared_error: 1.36 - ETA: 6s - loss: 1.3642 - mean_squared_error: 1.36 - ETA: 6s - loss: 1.3564 - mean_squared_error: 1.35 - ETA: 6s - loss: 1.3498 - mean_squared_error: 1.34 - ETA: 5s - loss: 1.3461 - mean_squared_error: 1.34 - ETA: 5s - loss: 1.3395 - mean_squared_error: 1.33 - ETA: 5s - loss: 1.3344 - mean_squared_error: 1.33 - ETA: 5s - loss: 1.3319 - mean_squared_error: 1.33 - ETA: 5s - loss: 1.3273 - mean_squared_error: 1.32 - ETA: 5s - loss: 1.3235 - mean_squared_error: 1.32 - ETA: 4s - loss: 1.3193 - mean_squared_error: 1.31 - ETA: 4s - loss: 1.3155 - mean_squared_error: 1.31 - ETA: 4s - loss: 1.3121 - mean_squared_error: 1.31 - ETA: 4s - loss: 1.3063 - mean_squared_error: 1.30 - ETA: 4s - loss: 1.3020 - mean_squared_error: 1.30 - ETA: 4s - loss: 1.2971 - mean_squared_error: 1.29 - ETA: 4s - loss: 1.2922 - mean_squared_error: 1.29 - ETA: 3s - loss: 1.2866 - mean_squared_error: 1.28 - ETA: 3s - loss: 1.2812 - mean_squared_error: 1.28 - ETA: 3s - loss: 1.2777 - mean_squared_error: 1.27 - ETA: 3s - loss: 1.2735 - mean_squared_error: 1.27 - ETA: 3s - loss: 1.2678 - mean_squared_error: 1.26 - ETA: 3s - loss: 1.2630 - mean_squared_error: 1.26 - ETA: 3s - loss: 1.2588 - mean_squared_error: 1.25 - ETA: 2s - loss: 1.2540 - mean_squared_error: 1.25 - ETA: 2s - loss: 1.2498 - mean_squared_error: 1.24 - ETA: 2s - loss: 1.2459 - mean_squared_error: 1.24 - ETA: 2s - loss: 1.2407 - mean_squared_error: 1.24 - ETA: 2s - loss: 1.2358 - mean_squared_error: 1.23 - ETA: 2s - loss: 1.2318 - mean_squared_error: 1.23 - ETA: 2s - loss: 1.2267 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2230 - mean_squared_error: 1.22 - ETA: 1s - loss: 1.2191 - mean_squared_error: 1.21 - ETA: 1s - loss: 1.2148 - mean_squared_error: 1.21 - ETA: 1s - loss: 1.2106 - mean_squared_error: 1.21 - ETA: 1s - loss: 1.2079 - mean_squared_error: 1.20 - ETA: 1s - loss: 1.2045 - mean_squared_error: 1.20 - ETA: 1s - loss: 1.2015 - mean_squared_error: 1.20 - ETA: 1s - loss: 1.1991 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1961 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1931 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1894 - mean_squared_error: 1.18 - ETA: 0s - loss: 1.1856 - mean_squared_error: 1.18 - ETA: 0s - loss: 1.1824 - mean_squared_error: 1.18 - ETA: 0s - loss: 1.1793 - mean_squared_error: 1.17 - ETA: 0s - loss: 1.1767 - mean_squared_error: 1.17 - ETA: 0s - loss: 1.1737 - mean_squared_error: 1.17 - 10s 2us/step - loss: 1.1707 - mean_squared_error: 1.1707\n",
      "Epoch 2/5\n",
      "4606789/4606789 [==============================] - ETA: 44s - loss: 0.9388 - mean_squared_error: 0.938 - ETA: 26s - loss: 0.9215 - mean_squared_error: 0.921 - ETA: 20s - loss: 0.9219 - mean_squared_error: 0.921 - ETA: 17s - loss: 0.9523 - mean_squared_error: 0.952 - ETA: 16s - loss: 0.9386 - mean_squared_error: 0.938 - ETA: 14s - loss: 0.9299 - mean_squared_error: 0.929 - ETA: 13s - loss: 0.9195 - mean_squared_error: 0.919 - ETA: 13s - loss: 0.9254 - mean_squared_error: 0.925 - ETA: 12s - loss: 0.9237 - mean_squared_error: 0.923 - ETA: 11s - loss: 0.9266 - mean_squared_error: 0.926 - ETA: 11s - loss: 0.9330 - mean_squared_error: 0.933 - ETA: 10s - loss: 0.9277 - mean_squared_error: 0.927 - ETA: 10s - loss: 0.9260 - mean_squared_error: 0.926 - ETA: 10s - loss: 0.9212 - mean_squared_error: 0.921 - ETA: 9s - loss: 0.9241 - mean_squared_error: 0.924 - ETA: 9s - loss: 0.9237 - mean_squared_error: 0.92 - ETA: 9s - loss: 0.9261 - mean_squared_error: 0.92 - ETA: 9s - loss: 0.9267 - mean_squared_error: 0.92 - ETA: 9s - loss: 0.9241 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9240 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9238 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9245 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9262 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9229 - mean_squared_error: 0.92 - ETA: 8s - loss: 0.9221 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9227 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9220 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9227 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9247 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9226 - mean_squared_error: 0.92 - ETA: 7s - loss: 0.9247 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9258 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9268 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9268 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9262 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9260 - mean_squared_error: 0.92 - ETA: 6s - loss: 0.9247 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9257 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9246 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9252 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9243 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9236 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9238 - mean_squared_error: 0.92 - ETA: 5s - loss: 0.9219 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9223 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9229 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9232 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9230 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9227 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9222 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9227 - mean_squared_error: 0.92 - ETA: 4s - loss: 0.9235 - mean_squared_error: 0.92 - ETA: 3s - loss: 0.9220 - mean_squared_error: 0.92 - ETA: 3s - loss: 0.9213 - mean_squared_error: 0.92 - ETA: 3s - loss: 0.9197 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9195 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9193 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9186 - mean_squared_error: 0.91 - ETA: 3s - loss: 0.9178 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9172 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9164 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9153 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9149 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9130 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9122 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9119 - mean_squared_error: 0.91 - ETA: 2s - loss: 0.9124 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9114 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9114 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9116 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9116 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9095 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9081 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9081 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9075 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9070 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9067 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9070 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9065 - mean_squared_error: 0.90 - 10s 2us/step - loss: 0.9068 - mean_squared_error: 0.9068\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4606789/4606789 [==============================] - ETA: 42s - loss: 0.8404 - mean_squared_error: 0.840 - ETA: 25s - loss: 0.8496 - mean_squared_error: 0.849 - ETA: 20s - loss: 0.8631 - mean_squared_error: 0.863 - ETA: 17s - loss: 0.8579 - mean_squared_error: 0.857 - ETA: 15s - loss: 0.8627 - mean_squared_error: 0.862 - ETA: 14s - loss: 0.8615 - mean_squared_error: 0.861 - ETA: 13s - loss: 0.8570 - mean_squared_error: 0.857 - ETA: 12s - loss: 0.8568 - mean_squared_error: 0.856 - ETA: 12s - loss: 0.8627 - mean_squared_error: 0.862 - ETA: 11s - loss: 0.8682 - mean_squared_error: 0.868 - ETA: 11s - loss: 0.8690 - mean_squared_error: 0.869 - ETA: 11s - loss: 0.8688 - mean_squared_error: 0.868 - ETA: 10s - loss: 0.8711 - mean_squared_error: 0.871 - ETA: 10s - loss: 0.8668 - mean_squared_error: 0.866 - ETA: 9s - loss: 0.8705 - mean_squared_error: 0.870 - ETA: 9s - loss: 0.8713 - mean_squared_error: 0.87 - ETA: 9s - loss: 0.8753 - mean_squared_error: 0.87 - ETA: 9s - loss: 0.8762 - mean_squared_error: 0.87 - ETA: 8s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8841 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8872 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8880 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8867 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8848 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8838 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8846 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8862 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8865 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8867 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8857 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8848 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8866 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8857 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8833 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8816 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8817 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8829 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8846 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8844 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8830 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8842 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8846 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8852 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8871 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8852 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8862 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8863 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8867 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8862 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8844 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8837 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8848 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8856 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8857 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8858 - mean_squared_error: 0.88 - 10s 2us/step - loss: 0.8849 - mean_squared_error: 0.8849\n",
      "Epoch 4/5\n",
      "4606789/4606789 [==============================] - ETA: 28s - loss: 0.9279 - mean_squared_error: 0.927 - ETA: 17s - loss: 0.9007 - mean_squared_error: 0.900 - ETA: 13s - loss: 0.9057 - mean_squared_error: 0.905 - ETA: 11s - loss: 0.8993 - mean_squared_error: 0.899 - ETA: 10s - loss: 0.8982 - mean_squared_error: 0.898 - ETA: 10s - loss: 0.8880 - mean_squared_error: 0.888 - ETA: 10s - loss: 0.8935 - mean_squared_error: 0.893 - ETA: 9s - loss: 0.8880 - mean_squared_error: 0.888 - ETA: 9s - loss: 0.9028 - mean_squared_error: 0.90 - ETA: 9s - loss: 0.8981 - mean_squared_error: 0.89 - ETA: 9s - loss: 0.8930 - mean_squared_error: 0.89 - ETA: 9s - loss: 0.8887 - mean_squared_error: 0.88 - ETA: 9s - loss: 0.8905 - mean_squared_error: 0.89 - ETA: 8s - loss: 0.8888 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8869 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8826 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8798 - mean_squared_error: 0.87 - ETA: 8s - loss: 0.8823 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8869 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8880 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8850 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8842 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8849 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8837 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8847 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8844 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8867 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8855 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8862 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8855 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8865 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8865 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8874 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8869 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8864 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8862 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8861 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8859 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8859 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8868 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8855 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8863 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8873 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8858 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8850 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8853 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8850 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8842 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8849 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8848 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8845 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8838 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8837 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8828 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8827 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8838 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8824 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8815 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8817 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8831 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8827 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8821 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8813 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8801 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8811 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8818 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8815 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8815 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8823 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8813 - mean_squared_error: 0.88 - 10s 2us/step - loss: 0.8812 - mean_squared_error: 0.8812\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4606789/4606789 [==============================] - ETA: 41s - loss: 0.8255 - mean_squared_error: 0.825 - ETA: 24s - loss: 0.8362 - mean_squared_error: 0.836 - ETA: 19s - loss: 0.8673 - mean_squared_error: 0.867 - ETA: 16s - loss: 0.8575 - mean_squared_error: 0.857 - ETA: 14s - loss: 0.8712 - mean_squared_error: 0.871 - ETA: 13s - loss: 0.8833 - mean_squared_error: 0.883 - ETA: 13s - loss: 0.8851 - mean_squared_error: 0.885 - ETA: 12s - loss: 0.8985 - mean_squared_error: 0.898 - ETA: 11s - loss: 0.8912 - mean_squared_error: 0.891 - ETA: 11s - loss: 0.8911 - mean_squared_error: 0.891 - ETA: 11s - loss: 0.8888 - mean_squared_error: 0.888 - ETA: 10s - loss: 0.8893 - mean_squared_error: 0.889 - ETA: 10s - loss: 0.8898 - mean_squared_error: 0.889 - ETA: 10s - loss: 0.8888 - mean_squared_error: 0.888 - ETA: 9s - loss: 0.8933 - mean_squared_error: 0.893 - ETA: 9s - loss: 0.8936 - mean_squared_error: 0.89 - ETA: 9s - loss: 0.8932 - mean_squared_error: 0.89 - ETA: 9s - loss: 0.8931 - mean_squared_error: 0.89 - ETA: 8s - loss: 0.8903 - mean_squared_error: 0.89 - ETA: 8s - loss: 0.8875 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8890 - mean_squared_error: 0.88 - ETA: 8s - loss: 0.8937 - mean_squared_error: 0.89 - ETA: 8s - loss: 0.8899 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8880 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8866 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8879 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8870 - mean_squared_error: 0.88 - ETA: 7s - loss: 0.8884 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8877 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8874 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8880 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8868 - mean_squared_error: 0.88 - ETA: 6s - loss: 0.8872 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8882 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8866 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8875 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8882 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8875 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8872 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8852 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 5s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8847 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8845 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8830 - mean_squared_error: 0.88 - ETA: 4s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8831 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8830 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8831 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8828 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8821 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8820 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8822 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8825 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8824 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8825 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8818 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8812 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8807 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8802 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8794 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8795 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8793 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8798 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8794 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8787 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8789 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8786 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8790 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8800 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8799 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8795 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8794 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8797 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8800 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8795 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8795 - mean_squared_error: 0.87 - 10s 2us/step - loss: 0.8788 - mean_squared_error: 0.8788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e188f6b978>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208444/208444 [==============================] - ETA:  - ETA:  - ETA:  - 0s 2us/step\n",
      "lightgbm runs for 51.58 seconds.\n",
      "Total running time was 8.63 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                               | 5/8 [36:59<22:43, 454.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month32\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.945583\n",
      "Test RMSE for SGDRegressor is 0.984203\n",
      "SGDRegressor runs for 12.83 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.843797\n",
      "Test RMSE for lightgbm is 0.938377\n",
      "lightgbm runs for 517.39 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "4815233/4815233 [==============================] - ETA: 1:46 - loss: 1.5669 - mean_squared_error: 1.56 - ETA: 58s - loss: 1.5473 - mean_squared_error: 1.5473 - ETA: 41s - loss: 1.5398 - mean_squared_error: 1.539 - ETA: 33s - loss: 1.5447 - mean_squared_error: 1.544 - ETA: 28s - loss: 1.5608 - mean_squared_error: 1.560 - ETA: 25s - loss: 1.5552 - mean_squared_error: 1.555 - ETA: 22s - loss: 1.5508 - mean_squared_error: 1.550 - ETA: 20s - loss: 1.5603 - mean_squared_error: 1.560 - ETA: 19s - loss: 1.5578 - mean_squared_error: 1.557 - ETA: 18s - loss: 1.5630 - mean_squared_error: 1.563 - ETA: 17s - loss: 1.5652 - mean_squared_error: 1.565 - ETA: 16s - loss: 1.5613 - mean_squared_error: 1.561 - ETA: 15s - loss: 1.5560 - mean_squared_error: 1.556 - ETA: 14s - loss: 1.5511 - mean_squared_error: 1.551 - ETA: 14s - loss: 1.5474 - mean_squared_error: 1.547 - ETA: 13s - loss: 1.5406 - mean_squared_error: 1.540 - ETA: 13s - loss: 1.5379 - mean_squared_error: 1.537 - ETA: 12s - loss: 1.5394 - mean_squared_error: 1.539 - ETA: 12s - loss: 1.5439 - mean_squared_error: 1.543 - ETA: 11s - loss: 1.5378 - mean_squared_error: 1.537 - ETA: 11s - loss: 1.5381 - mean_squared_error: 1.538 - ETA: 11s - loss: 1.5496 - mean_squared_error: 1.549 - ETA: 10s - loss: 1.5480 - mean_squared_error: 1.548 - ETA: 10s - loss: 1.5438 - mean_squared_error: 1.543 - ETA: 10s - loss: 1.5415 - mean_squared_error: 1.541 - ETA: 10s - loss: 1.5382 - mean_squared_error: 1.538 - ETA: 9s - loss: 1.5367 - mean_squared_error: 1.536 - ETA: 9s - loss: 1.5374 - mean_squared_error: 1.53 - ETA: 9s - loss: 1.5373 - mean_squared_error: 1.53 - ETA: 9s - loss: 1.5381 - mean_squared_error: 1.53 - ETA: 8s - loss: 1.5391 - mean_squared_error: 1.53 - ETA: 8s - loss: 1.5423 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5402 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5388 - mean_squared_error: 1.53 - ETA: 8s - loss: 1.5388 - mean_squared_error: 1.53 - ETA: 7s - loss: 1.5404 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5386 - mean_squared_error: 1.53 - ETA: 7s - loss: 1.5412 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5411 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5428 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5444 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5412 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5443 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5458 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5484 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5460 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5456 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5452 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5457 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5435 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5432 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5413 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5417 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5410 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5413 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5404 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5390 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5388 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5401 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5386 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5395 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5414 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5417 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5425 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5422 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5413 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5412 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5412 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5415 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5394 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5408 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5421 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5420 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5434 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5425 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5425 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5407 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5401 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5420 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5415 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5421 - mean_squared_error: 1.54 - 12s 2us/step - loss: 1.5412 - mean_squared_error: 1.5412\n",
      "Epoch 2/5\n",
      "4815233/4815233 [==============================] - ETA: 44s - loss: 1.5252 - mean_squared_error: 1.525 - ETA: 26s - loss: 1.5340 - mean_squared_error: 1.534 - ETA: 20s - loss: 1.4941 - mean_squared_error: 1.494 - ETA: 17s - loss: 1.4864 - mean_squared_error: 1.486 - ETA: 16s - loss: 1.5192 - mean_squared_error: 1.519 - ETA: 14s - loss: 1.5229 - mean_squared_error: 1.522 - ETA: 14s - loss: 1.5412 - mean_squared_error: 1.541 - ETA: 13s - loss: 1.5500 - mean_squared_error: 1.550 - ETA: 12s - loss: 1.5359 - mean_squared_error: 1.535 - ETA: 12s - loss: 1.5320 - mean_squared_error: 1.532 - ETA: 11s - loss: 1.5321 - mean_squared_error: 1.532 - ETA: 11s - loss: 1.5370 - mean_squared_error: 1.537 - ETA: 11s - loss: 1.5307 - mean_squared_error: 1.530 - ETA: 10s - loss: 1.5360 - mean_squared_error: 1.536 - ETA: 10s - loss: 1.5355 - mean_squared_error: 1.535 - ETA: 10s - loss: 1.5427 - mean_squared_error: 1.542 - ETA: 10s - loss: 1.5516 - mean_squared_error: 1.551 - ETA: 9s - loss: 1.5544 - mean_squared_error: 1.554 - ETA: 9s - loss: 1.5604 - mean_squared_error: 1.56 - ETA: 9s - loss: 1.5586 - mean_squared_error: 1.55 - ETA: 9s - loss: 1.5665 - mean_squared_error: 1.56 - ETA: 8s - loss: 1.5697 - mean_squared_error: 1.56 - ETA: 8s - loss: 1.5650 - mean_squared_error: 1.56 - ETA: 8s - loss: 1.5648 - mean_squared_error: 1.56 - ETA: 8s - loss: 1.5624 - mean_squared_error: 1.56 - ETA: 8s - loss: 1.5562 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5586 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5596 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5612 - mean_squared_error: 1.56 - ETA: 7s - loss: 1.5615 - mean_squared_error: 1.56 - ETA: 7s - loss: 1.5558 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5567 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5591 - mean_squared_error: 1.55 - ETA: 6s - loss: 1.5595 - mean_squared_error: 1.55 - ETA: 6s - loss: 1.5619 - mean_squared_error: 1.56 - ETA: 6s - loss: 1.5649 - mean_squared_error: 1.56 - ETA: 6s - loss: 1.5616 - mean_squared_error: 1.56 - ETA: 6s - loss: 1.5600 - mean_squared_error: 1.56 - ETA: 6s - loss: 1.5587 - mean_squared_error: 1.55 - ETA: 6s - loss: 1.5584 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5569 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5567 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5552 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5547 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5549 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5578 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5591 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5593 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5579 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5578 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5577 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5555 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5543 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5549 - mean_squared_error: 1.55 - ETA: 4s - loss: 1.5549 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5562 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5546 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5545 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5550 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5548 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5550 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5548 - mean_squared_error: 1.55 - ETA: 3s - loss: 1.5539 - mean_squared_error: 1.55 - ETA: 2s - loss: 1.5542 - mean_squared_error: 1.55 - ETA: 2s - loss: 1.5527 - mean_squared_error: 1.55 - ETA: 2s - loss: 1.5512 - mean_squared_error: 1.55 - ETA: 2s - loss: 1.5513 - mean_squared_error: 1.55 - ETA: 2s - loss: 1.5489 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5485 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5472 - mean_squared_error: 1.54 - ETA: 2s - loss: 1.5458 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5453 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5446 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5453 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5443 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5428 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5436 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5435 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5443 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5447 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5433 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5427 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5414 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5410 - mean_squared_error: 1.54 - 11s 2us/step - loss: 1.5412 - mean_squared_error: 1.5412\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815233/4815233 [==============================] - ETA: 44s - loss: 1.5312 - mean_squared_error: 1.531 - ETA: 26s - loss: 1.5328 - mean_squared_error: 1.532 - ETA: 19s - loss: 1.5391 - mean_squared_error: 1.539 - ETA: 16s - loss: 1.5410 - mean_squared_error: 1.541 - ETA: 14s - loss: 1.5458 - mean_squared_error: 1.545 - ETA: 13s - loss: 1.5393 - mean_squared_error: 1.539 - ETA: 13s - loss: 1.5287 - mean_squared_error: 1.528 - ETA: 12s - loss: 1.5243 - mean_squared_error: 1.524 - ETA: 12s - loss: 1.5205 - mean_squared_error: 1.520 - ETA: 11s - loss: 1.5366 - mean_squared_error: 1.536 - ETA: 11s - loss: 1.5279 - mean_squared_error: 1.527 - ETA: 11s - loss: 1.5362 - mean_squared_error: 1.536 - ETA: 10s - loss: 1.5331 - mean_squared_error: 1.533 - ETA: 10s - loss: 1.5381 - mean_squared_error: 1.538 - ETA: 10s - loss: 1.5428 - mean_squared_error: 1.542 - ETA: 10s - loss: 1.5402 - mean_squared_error: 1.540 - ETA: 9s - loss: 1.5406 - mean_squared_error: 1.540 - ETA: 9s - loss: 1.5371 - mean_squared_error: 1.53 - ETA: 9s - loss: 1.5391 - mean_squared_error: 1.53 - ETA: 9s - loss: 1.5389 - mean_squared_error: 1.53 - ETA: 8s - loss: 1.5410 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5379 - mean_squared_error: 1.53 - ETA: 8s - loss: 1.5403 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5430 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5453 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5434 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5456 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5444 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5451 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5451 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5425 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5479 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5480 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5463 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5483 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5488 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5484 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5516 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5522 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5493 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5479 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5468 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5488 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5500 - mean_squared_error: 1.55 - ETA: 5s - loss: 1.5485 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5455 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5438 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5437 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5436 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5430 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5414 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5407 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5414 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5418 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5424 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5427 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5405 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5407 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5385 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5379 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5375 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5368 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5383 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5389 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5389 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5398 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5377 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5371 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5381 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5377 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5381 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5394 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5382 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5367 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5374 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5385 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5391 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5405 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5404 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5402 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5404 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5404 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5406 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5413 - mean_squared_error: 1.54 - 11s 2us/step - loss: 1.5412 - mean_squared_error: 1.5412\n",
      "Epoch 4/5\n",
      "4815233/4815233 [==============================] - ETA: 47s - loss: 1.4538 - mean_squared_error: 1.453 - ETA: 27s - loss: 1.5493 - mean_squared_error: 1.549 - ETA: 20s - loss: 1.5383 - mean_squared_error: 1.538 - ETA: 17s - loss: 1.5370 - mean_squared_error: 1.537 - ETA: 15s - loss: 1.5409 - mean_squared_error: 1.540 - ETA: 13s - loss: 1.5445 - mean_squared_error: 1.544 - ETA: 12s - loss: 1.5410 - mean_squared_error: 1.541 - ETA: 11s - loss: 1.5445 - mean_squared_error: 1.544 - ETA: 11s - loss: 1.5456 - mean_squared_error: 1.545 - ETA: 11s - loss: 1.5563 - mean_squared_error: 1.556 - ETA: 10s - loss: 1.5543 - mean_squared_error: 1.554 - ETA: 10s - loss: 1.5518 - mean_squared_error: 1.551 - ETA: 10s - loss: 1.5528 - mean_squared_error: 1.552 - ETA: 10s - loss: 1.5516 - mean_squared_error: 1.551 - ETA: 9s - loss: 1.5513 - mean_squared_error: 1.551 - ETA: 9s - loss: 1.5477 - mean_squared_error: 1.54 - ETA: 9s - loss: 1.5491 - mean_squared_error: 1.54 - ETA: 9s - loss: 1.5537 - mean_squared_error: 1.55 - ETA: 9s - loss: 1.5523 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5490 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5475 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5531 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5535 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5508 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5501 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5515 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5525 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5526 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5561 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5552 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5504 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5501 - mean_squared_error: 1.55 - ETA: 7s - loss: 1.5494 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5503 - mean_squared_error: 1.55 - ETA: 6s - loss: 1.5469 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5464 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5450 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5446 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5448 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5444 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5427 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5436 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5460 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5437 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5466 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5474 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5460 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5492 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5470 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5463 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5443 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5430 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5415 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5419 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5408 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5395 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5388 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5376 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5387 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5383 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5372 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5386 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5389 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5383 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5380 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5372 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5367 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5372 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5367 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5367 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5365 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5372 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5383 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5378 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5384 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5383 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5392 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5390 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5393 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5397 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5395 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5405 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5407 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5412 - mean_squared_error: 1.54 - 10s 2us/step - loss: 1.5412 - mean_squared_error: 1.5412\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815233/4815233 [==============================] - ETA: 43s - loss: 1.6876 - mean_squared_error: 1.687 - ETA: 25s - loss: 1.5904 - mean_squared_error: 1.590 - ETA: 20s - loss: 1.5603 - mean_squared_error: 1.560 - ETA: 17s - loss: 1.5299 - mean_squared_error: 1.529 - ETA: 16s - loss: 1.5183 - mean_squared_error: 1.518 - ETA: 14s - loss: 1.5346 - mean_squared_error: 1.534 - ETA: 13s - loss: 1.5451 - mean_squared_error: 1.545 - ETA: 13s - loss: 1.5607 - mean_squared_error: 1.560 - ETA: 12s - loss: 1.5759 - mean_squared_error: 1.575 - ETA: 12s - loss: 1.5721 - mean_squared_error: 1.572 - ETA: 11s - loss: 1.5644 - mean_squared_error: 1.564 - ETA: 11s - loss: 1.5661 - mean_squared_error: 1.566 - ETA: 11s - loss: 1.5695 - mean_squared_error: 1.569 - ETA: 10s - loss: 1.5637 - mean_squared_error: 1.563 - ETA: 10s - loss: 1.5597 - mean_squared_error: 1.559 - ETA: 10s - loss: 1.5615 - mean_squared_error: 1.561 - ETA: 10s - loss: 1.5643 - mean_squared_error: 1.564 - ETA: 9s - loss: 1.5602 - mean_squared_error: 1.560 - ETA: 9s - loss: 1.5582 - mean_squared_error: 1.55 - ETA: 9s - loss: 1.5566 - mean_squared_error: 1.55 - ETA: 9s - loss: 1.5542 - mean_squared_error: 1.55 - ETA: 9s - loss: 1.5500 - mean_squared_error: 1.55 - ETA: 8s - loss: 1.5475 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5453 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5450 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5417 - mean_squared_error: 1.54 - ETA: 8s - loss: 1.5427 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5460 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5479 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5458 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5484 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5438 - mean_squared_error: 1.54 - ETA: 7s - loss: 1.5401 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5394 - mean_squared_error: 1.53 - ETA: 6s - loss: 1.5428 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5442 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5441 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5449 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5466 - mean_squared_error: 1.54 - ETA: 6s - loss: 1.5474 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5448 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5443 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5458 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5455 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5457 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5433 - mean_squared_error: 1.54 - ETA: 5s - loss: 1.5430 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5435 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5418 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5422 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5429 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5421 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5395 - mean_squared_error: 1.53 - ETA: 4s - loss: 1.5405 - mean_squared_error: 1.54 - ETA: 4s - loss: 1.5406 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5399 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5403 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5416 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5419 - mean_squared_error: 1.54 - ETA: 3s - loss: 1.5397 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5385 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5387 - mean_squared_error: 1.53 - ETA: 3s - loss: 1.5381 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5354 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5352 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5354 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5369 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5353 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5366 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5351 - mean_squared_error: 1.53 - ETA: 2s - loss: 1.5369 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5367 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5362 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5375 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5392 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5403 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5394 - mean_squared_error: 1.53 - ETA: 1s - loss: 1.5403 - mean_squared_error: 1.54 - ETA: 1s - loss: 1.5403 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5397 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5399 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5394 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5395 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5385 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5392 - mean_squared_error: 1.53 - ETA: 0s - loss: 1.5414 - mean_squared_error: 1.54 - ETA: 0s - loss: 1.5416 - mean_squared_error: 1.54 - 11s 2us/step - loss: 1.5412 - mean_squared_error: 1.5412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1a2af8e48>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208075/208075 [==============================] - ETA:  - ETA:  - 0s 2us/step\n",
      "lightgbm runs for 55.19 seconds.\n",
      "Total running time was 9.78 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                    | 6/8 [46:47<16:28, 494.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month33\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.951246\n",
      "Test RMSE for SGDRegressor is 0.908068\n",
      "SGDRegressor runs for 11.84 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.844980\n",
      "Test RMSE for lightgbm is 0.835610\n",
      "lightgbm runs for 504.42 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "5023308/5023308 [==============================] - ETA: 30s - loss: 1.5388 - mean_squared_error: 1.538 - ETA: 11s - loss: 1.5435 - mean_squared_error: 1.543 - ETA: 7s - loss: 1.5013 - mean_squared_error: 1.501 - ETA: 5s - loss: 1.4648 - mean_squared_error: 1.46 - ETA: 4s - loss: 1.4365 - mean_squared_error: 1.43 - ETA: 4s - loss: 1.4235 - mean_squared_error: 1.42 - ETA: 3s - loss: 1.4389 - mean_squared_error: 1.43 - ETA: 3s - loss: 1.4388 - mean_squared_error: 1.43 - ETA: 3s - loss: 1.4313 - mean_squared_error: 1.43 - ETA: 3s - loss: 1.4255 - mean_squared_error: 1.42 - ETA: 2s - loss: 1.4207 - mean_squared_error: 1.42 - ETA: 2s - loss: 1.4181 - mean_squared_error: 1.41 - ETA: 2s - loss: 1.4118 - mean_squared_error: 1.41 - ETA: 2s - loss: 1.4013 - mean_squared_error: 1.40 - ETA: 2s - loss: 1.3925 - mean_squared_error: 1.39 - ETA: 2s - loss: 1.3823 - mean_squared_error: 1.38 - ETA: 2s - loss: 1.3750 - mean_squared_error: 1.37 - ETA: 1s - loss: 1.3677 - mean_squared_error: 1.36 - ETA: 1s - loss: 1.3581 - mean_squared_error: 1.35 - ETA: 1s - loss: 1.3486 - mean_squared_error: 1.34 - ETA: 1s - loss: 1.3388 - mean_squared_error: 1.33 - ETA: 1s - loss: 1.3265 - mean_squared_error: 1.32 - ETA: 1s - loss: 1.3180 - mean_squared_error: 1.31 - ETA: 1s - loss: 1.3133 - mean_squared_error: 1.31 - ETA: 1s - loss: 1.3016 - mean_squared_error: 1.30 - ETA: 1s - loss: 1.2925 - mean_squared_error: 1.29 - ETA: 1s - loss: 1.2831 - mean_squared_error: 1.28 - ETA: 1s - loss: 1.2750 - mean_squared_error: 1.27 - ETA: 1s - loss: 1.2678 - mean_squared_error: 1.26 - ETA: 0s - loss: 1.2587 - mean_squared_error: 1.25 - ETA: 0s - loss: 1.2514 - mean_squared_error: 1.25 - ETA: 0s - loss: 1.2427 - mean_squared_error: 1.24 - ETA: 0s - loss: 1.2356 - mean_squared_error: 1.23 - ETA: 0s - loss: 1.2275 - mean_squared_error: 1.22 - ETA: 0s - loss: 1.2207 - mean_squared_error: 1.22 - ETA: 0s - loss: 1.2137 - mean_squared_error: 1.21 - ETA: 0s - loss: 1.2070 - mean_squared_error: 1.20 - ETA: 0s - loss: 1.1992 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1938 - mean_squared_error: 1.19 - ETA: 0s - loss: 1.1890 - mean_squared_error: 1.18 - ETA: 0s - loss: 1.1846 - mean_squared_error: 1.18 - ETA: 0s - loss: 1.1781 - mean_squared_error: 1.17 - ETA: 0s - loss: 1.1722 - mean_squared_error: 1.17 - ETA: 0s - loss: 1.1678 - mean_squared_error: 1.16 - ETA: 0s - loss: 1.1634 - mean_squared_error: 1.16 - 3s 1us/step - loss: 1.1630 - mean_squared_error: 1.1630\n",
      "Epoch 2/5\n",
      "5023308/5023308 [==============================] - ETA: 13s - loss: 0.9621 - mean_squared_error: 0.962 - ETA: 5s - loss: 0.9583 - mean_squared_error: 0.958 - ETA: 4s - loss: 0.9584 - mean_squared_error: 0.95 - ETA: 3s - loss: 0.9671 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9621 - mean_squared_error: 0.96 - ETA: 3s - loss: 0.9462 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9419 - mean_squared_error: 0.94 - ETA: 2s - loss: 0.9362 - mean_squared_error: 0.93 - ETA: 2s - loss: 0.9281 - mean_squared_error: 0.92 - ETA: 2s - loss: 0.9297 - mean_squared_error: 0.92 - ETA: 2s - loss: 0.9293 - mean_squared_error: 0.92 - ETA: 2s - loss: 0.9272 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9286 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9238 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9235 - mean_squared_error: 0.92 - ETA: 1s - loss: 0.9198 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9169 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9145 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9128 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9120 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9152 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9144 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9090 - mean_squared_error: 0.90 - ETA: 1s - loss: 0.9122 - mean_squared_error: 0.91 - ETA: 1s - loss: 0.9121 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9114 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9095 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9096 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9095 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9086 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9101 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9100 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9109 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9103 - mean_squared_error: 0.91 - ETA: 0s - loss: 0.9085 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9078 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9065 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9056 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9046 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9047 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9037 - mean_squared_error: 0.90 - ETA: 0s - loss: 0.9035 - mean_squared_error: 0.90 - 3s 1us/step - loss: 0.9038 - mean_squared_error: 0.9038\n",
      "Epoch 3/5\n",
      "5023308/5023308 [==============================] - ETA: 13s - loss: 0.9568 - mean_squared_error: 0.956 - ETA: 5s - loss: 0.9134 - mean_squared_error: 0.913 - ETA: 4s - loss: 0.8883 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8884 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8910 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8914 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8880 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8842 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8869 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8849 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8824 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8834 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8805 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8848 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8863 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8840 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8818 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8835 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8844 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8822 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8845 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8864 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8854 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8854 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8845 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8850 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8841 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8843 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8851 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8856 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8846 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8854 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8856 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8865 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8860 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8842 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8817 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8815 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8801 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8809 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8806 - mean_squared_error: 0.88 - ETA: 0s - loss: 0.8794 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8793 - mean_squared_error: 0.87 - 3s 1us/step - loss: 0.8795 - mean_squared_error: 0.8795\n",
      "Epoch 4/5\n",
      "5023308/5023308 [==============================] - ETA: 13s - loss: 0.9233 - mean_squared_error: 0.923 - ETA: 5s - loss: 0.9065 - mean_squared_error: 0.906 - ETA: 4s - loss: 0.8947 - mean_squared_error: 0.89 - ETA: 3s - loss: 0.9007 - mean_squared_error: 0.90 - ETA: 3s - loss: 0.8953 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8904 - mean_squared_error: 0.89 - ETA: 2s - loss: 0.8836 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8733 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8758 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8770 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8769 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8745 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8750 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8745 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8785 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8779 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8769 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8749 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8733 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8742 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8735 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8733 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8722 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8724 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8752 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8762 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8745 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8740 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8729 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8743 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8741 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8746 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8738 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8733 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8736 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8743 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8746 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8754 - mean_squared_error: 0.87 - 3s 1us/step - loss: 0.8757 - mean_squared_error: 0.8757\n",
      "Epoch 5/5\n",
      "5023308/5023308 [==============================] - ETA: 13s - loss: 0.8407 - mean_squared_error: 0.840 - ETA: 5s - loss: 0.8773 - mean_squared_error: 0.877 - ETA: 4s - loss: 0.8828 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8839 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8832 - mean_squared_error: 0.88 - ETA: 3s - loss: 0.8794 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8817 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8820 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8867 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8855 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8841 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8823 - mean_squared_error: 0.88 - ETA: 2s - loss: 0.8784 - mean_squared_error: 0.87 - ETA: 2s - loss: 0.8759 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8737 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8745 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8749 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8769 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8786 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8812 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8815 - mean_squared_error: 0.88 - ETA: 1s - loss: 0.8797 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8776 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8739 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8740 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8770 - mean_squared_error: 0.87 - ETA: 1s - loss: 0.8750 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8746 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8751 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8746 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8731 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8737 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8719 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8736 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8732 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8738 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8735 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8747 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8748 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8750 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8750 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8738 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8735 - mean_squared_error: 0.87 - ETA: 0s - loss: 0.8732 - mean_squared_error: 0.87 - 3s 1us/step - loss: 0.8734 - mean_squared_error: 0.8734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1a2c759b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221802/221802 [==============================] - ETA:  - 0s 0us/step\n",
      "lightgbm runs for 13.29 seconds.\n",
      "Total running time was 8.85 minutes.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹          | 7/8 [55:38<08:25, 505.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Start training for month34\n",
      "Training Model 0: SGDRegressor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
       "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
       "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
       "       random_state=0, shuffle=True, tol=None, validation_fraction=0.1,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE for SGDRegressor is 0.948541\n",
      "Test RMSE for SGDRegressor is 0.866021\n",
      "SGDRegressor runs for 5.97 seconds.\n",
      "\n",
      "Training Model 1: lightgbm\n",
      "Train RMSE for lightgbm is 0.843268\n",
      "Test RMSE for lightgbm is 0.829173\n",
      "lightgbm runs for 480.82 seconds.\n",
      "\n",
      "Training Model 2: keras\n",
      "Epoch 1/5\n",
      "4455000/5245110 [========================>.....] - ETA: 2:05 - loss: 1.4264 - mean_squared_error: 1.42 - ETA: 1:08 - loss: 1.5130 - mean_squared_error: 1.51 - ETA: 48s - loss: 1.4962 - mean_squared_error: 1.4962 - ETA: 38s - loss: 1.4912 - mean_squared_error: 1.491 - ETA: 32s - loss: 1.4958 - mean_squared_error: 1.495 - ETA: 28s - loss: 1.4857 - mean_squared_error: 1.485 - ETA: 26s - loss: 1.4876 - mean_squared_error: 1.487 - ETA: 23s - loss: 1.4893 - mean_squared_error: 1.489 - ETA: 22s - loss: 1.4804 - mean_squared_error: 1.480 - ETA: 20s - loss: 1.4796 - mean_squared_error: 1.479 - ETA: 19s - loss: 1.4657 - mean_squared_error: 1.465 - ETA: 18s - loss: 1.4670 - mean_squared_error: 1.467 - ETA: 17s - loss: 1.4579 - mean_squared_error: 1.457 - ETA: 16s - loss: 1.4529 - mean_squared_error: 1.452 - ETA: 15s - loss: 1.4424 - mean_squared_error: 1.442 - ETA: 15s - loss: 1.4402 - mean_squared_error: 1.440 - ETA: 14s - loss: 1.4309 - mean_squared_error: 1.430 - ETA: 14s - loss: 1.4306 - mean_squared_error: 1.430 - ETA: 13s - loss: 1.4259 - mean_squared_error: 1.425 - ETA: 13s - loss: 1.4256 - mean_squared_error: 1.425 - ETA: 13s - loss: 1.4223 - mean_squared_error: 1.422 - ETA: 12s - loss: 1.4181 - mean_squared_error: 1.418 - ETA: 12s - loss: 1.4141 - mean_squared_error: 1.414 - ETA: 12s - loss: 1.4065 - mean_squared_error: 1.406 - ETA: 11s - loss: 1.4046 - mean_squared_error: 1.404 - ETA: 11s - loss: 1.3999 - mean_squared_error: 1.399 - ETA: 11s - loss: 1.3939 - mean_squared_error: 1.393 - ETA: 10s - loss: 1.3890 - mean_squared_error: 1.389 - ETA: 10s - loss: 1.3857 - mean_squared_error: 1.385 - ETA: 10s - loss: 1.3874 - mean_squared_error: 1.387 - ETA: 10s - loss: 1.3817 - mean_squared_error: 1.381 - ETA: 10s - loss: 1.3763 - mean_squared_error: 1.376 - ETA: 9s - loss: 1.3729 - mean_squared_error: 1.372 - ETA: 9s - loss: 1.3689 - mean_squared_error: 1.36 - ETA: 9s - loss: 1.3659 - mean_squared_error: 1.36 - ETA: 9s - loss: 1.3581 - mean_squared_error: 1.35 - ETA: 8s - loss: 1.3534 - mean_squared_error: 1.35 - ETA: 8s - loss: 1.3495 - mean_squared_error: 1.34 - ETA: 8s - loss: 1.3452 - mean_squared_error: 1.34 - ETA: 8s - loss: 1.3398 - mean_squared_error: 1.33 - ETA: 8s - loss: 1.3349 - mean_squared_error: 1.33 - ETA: 7s - loss: 1.3320 - mean_squared_error: 1.33 - ETA: 7s - loss: 1.3263 - mean_squared_error: 1.32 - ETA: 7s - loss: 1.3226 - mean_squared_error: 1.32 - ETA: 7s - loss: 1.3168 - mean_squared_error: 1.31 - ETA: 7s - loss: 1.3120 - mean_squared_error: 1.31 - ETA: 7s - loss: 1.3063 - mean_squared_error: 1.30 - ETA: 6s - loss: 1.3027 - mean_squared_error: 1.30 - ETA: 6s - loss: 1.2970 - mean_squared_error: 1.29 - ETA: 6s - loss: 1.2931 - mean_squared_error: 1.29 - ETA: 6s - loss: 1.2881 - mean_squared_error: 1.28 - ETA: 6s - loss: 1.2837 - mean_squared_error: 1.28 - ETA: 6s - loss: 1.2778 - mean_squared_error: 1.27 - ETA: 5s - loss: 1.2727 - mean_squared_error: 1.27 - ETA: 5s - loss: 1.2670 - mean_squared_error: 1.26 - ETA: 5s - loss: 1.2601 - mean_squared_error: 1.26 - ETA: 5s - loss: 1.2547 - mean_squared_error: 1.25 - ETA: 5s - loss: 1.2503 - mean_squared_error: 1.25 - ETA: 5s - loss: 1.2468 - mean_squared_error: 1.24 - ETA: 4s - loss: 1.2433 - mean_squared_error: 1.24 - ETA: 4s - loss: 1.2406 - mean_squared_error: 1.24 - ETA: 4s - loss: 1.2365 - mean_squared_error: 1.23 - ETA: 4s - loss: 1.2332 - mean_squared_error: 1.23 - ETA: 4s - loss: 1.2293 - mean_squared_error: 1.22 - ETA: 4s - loss: 1.2254 - mean_squared_error: 1.22 - ETA: 4s - loss: 1.2224 - mean_squared_error: 1.22 - ETA: 3s - loss: 1.2189 - mean_squared_error: 1.21 - ETA: 3s - loss: 1.2153 - mean_squared_error: 1.21 - ETA: 3s - loss: 1.2110 - mean_squared_error: 1.21 - ETA: 3s - loss: 1.2074 - mean_squared_error: 1.20 - ETA: 3s - loss: 1.2027 - mean_squared_error: 1.20 - ETA: 3s - loss: 1.1998 - mean_squared_error: 1.19 - ETA: 3s - loss: 1.1957 - mean_squared_error: 1.19 - ETA: 2s - loss: 1.1912 - mean_squared_error: 1.19 - ETA: 2s - loss: 1.1898 - mean_squared_error: 1.18 - ETA: 2s - loss: 1.1874 - mean_squared_error: 1.18 - ETA: 2s - loss: 1.1845 - mean_squared_error: 1.18 - ETA: 2s - loss: 1.1818 - mean_squared_error: 1.18 - ETA: 2s - loss: 1.1782 - mean_squared_error: 1.17 - ETA: 2s - loss: 1.1753 - mean_squared_error: 1.17 - ETA: 1s - loss: 1.1721 - mean_squared_error: 1.1721"
     ]
    }
   ],
   "source": [
    "%time\n",
    "SEED = 0\n",
    "for cur_block_num in tqdm(months_to_generate_meta_features):\n",
    "    print('-' * 50)\n",
    "    print('Start training for month%d'% cur_block_num)\n",
    "    start_cur_month = time.perf_counter()\n",
    "    cur_X_train = all_data.loc[dates <  cur_block_num][feature_columns]\n",
    "    cur_X_test =  all_data.loc[dates == cur_block_num][feature_columns]\n",
    "    cur_y_train = all_data.loc[dates <  cur_block_num, Target].values\n",
    "    cur_y_test =  all_data.loc[dates == cur_block_num, Target].values\n",
    "    # Create Numpy arrays of train, test and target dataframes to feed into models\n",
    "    train_x = cur_X_train.values\n",
    "    train_y = cur_y_train.ravel()\n",
    "    test_x = cur_X_test.values\n",
    "    test_y = cur_y_test.ravel()\n",
    "    \n",
    "    preds = []\n",
    "    from sklearn.linear_model import (LinearRegression, SGDRegressor)\n",
    "    import lightgbm as lgb\n",
    "    sgdr= SGDRegressor(\n",
    "        penalty = 'l2' ,\n",
    "        random_state = SEED )\n",
    "    lgb_params = {\n",
    "        'feature_fraction': 0.75,\n",
    "        'metric': 'rmse',\n",
    "        'nthread':1,\n",
    "        'min_data_in_leaf': 2**7,\n",
    "        'bagging_fraction': 0.75,\n",
    "        'learning_rate': 0.03,\n",
    "        'objective': 'mse',\n",
    "        'bagging_seed': 2**7,\n",
    "        'num_leaves': 2**7,\n",
    "        'bagging_freq':1,\n",
    "        'verbose':0}\n",
    "    estimators = [sgdr]\n",
    "    for estimator in estimators:\n",
    "        print('Training Model %d: %s'%(len(preds), estimator.__class__.__name__))\n",
    "        start = time.perf_counter()\n",
    "        estimator.fit(train_x, train_y)\n",
    "        pred_test = estimator.predict(test_x)\n",
    "        preds.append(pred_test)\n",
    "\n",
    "        pred_train = estimator.predict(train_x)\n",
    "        print('Train RMSE for %s is %f' % (estimator.__class__.__name__, sqrt(mean_squared_error(cur_y_train, pred_train))))\n",
    "        print('Test RMSE for %s is %f' % (estimator.__class__.__name__, sqrt(mean_squared_error(cur_y_test, pred_test))))\n",
    "\n",
    "        run = time.perf_counter() - start\n",
    "        print('{} runs for {:.2f} seconds.'.format(estimator.__class__.__name__, run))\n",
    "        print()\n",
    "#         import pickle\n",
    "#         pickle.dump(estimator, open(filename, 'wb'))\n",
    "\n",
    "    print('Training Model %d: %s'%(len(preds), 'lightgbm'))\n",
    "    start = time.perf_counter()\n",
    "    estimator = lgb.train(lgb_params, lgb.Dataset(train_x, label=train_y), 300)\n",
    "    pred_test = estimator.predict(test_x)\n",
    "    preds.append(pred_test)\n",
    "\n",
    "    pred_train = estimator.predict(train_x)\n",
    "    print('Train RMSE for %s is %f' % ('lightgbm', sqrt(mean_squared_error(cur_y_train, pred_train))))\n",
    "    print('Test RMSE for %s is %f' % ('lightgbm', sqrt(mean_squared_error(cur_y_test, pred_test))))\n",
    "\n",
    "    run = time.perf_counter() - start\n",
    "    print('{} runs for {:.2f} seconds.'.format('lightgbm', run))\n",
    "    print()\n",
    "\n",
    "    print('Training Model %d: %s'%(len(preds), 'keras'))\n",
    "    start = time.perf_counter()\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "    def baseline_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=train_x.shape[1], kernel_initializer='uniform', activation='softplus'))\n",
    "        model.add(Dense(1, kernel_initializer='uniform', activation = 'relu'))\n",
    "        # Compile model\n",
    "        model.compile(loss='mse', optimizer='Nadam', metrics=['mse'])\n",
    "        # model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "\n",
    "    estimator = KerasRegressor(build_fn=baseline_model, verbose=1, epochs=5, batch_size = 55000)\n",
    "    estimator.fit(train_x, train_y)\n",
    "    pred_test = estimator.predict(test_x)\n",
    "    preds.append(pred_test)\n",
    "    run = time.perf_counter() - start\n",
    "    print('{} runs for {:.2f} seconds.'.format('lightgbm', run))\n",
    "\n",
    "    cur_month_run_total = time.perf_counter() - start_cur_month\n",
    "    print('Total running time was {:.2f} minutes.'.format(cur_month_run_total/60))\n",
    "    print('-' * 50)\n",
    "\n",
    "    slice_end = slice_start + cur_X_test.shape[0]\n",
    "    X_all_level2[ slice_start : slice_end , :] = np.c_[preds].transpose()\n",
    "    slice_start = slice_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "test_nrow = len(preds[0])\n",
    "X_train_level2 = X_all_level2[ : -test_nrow, :]\n",
    "X_test_level2 = X_all_level2[ -test_nrow: , :]\n",
    "y_train_level2 = y_all_level2[ : -test_nrow]\n",
    "y_test_level2 = y_all_level2[ -test_nrow : ]\n",
    "print('%0.2f min: Finish training First level models'%((time.perf_counter() - start_first_level_total)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Second level learning model via linear regression\n",
    "print('Training Second level learning model via linear regression')\n",
    "from sklearn.linear_model import (LinearRegression, SGDRegressor)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_level2, y_train_level2)\n",
    "# Compute R-squared on the train and test sets.\n",
    "# print('Train R-squared for %s is %f' %('test_preds_lr_stacking', sqrt(mean_squared_error(y_train_level2, lr.predict(X_train_level2)))))\n",
    "test_preds_lr_stacking = lr.predict(X_test_level2)\n",
    "train_preds_lr_stacking = lr.predict(X_train_level2)\n",
    "print('Train R-squared for %s is %f' %('train_preds_lr_stacking', sqrt(mean_squared_error(y_train_level2, train_preds_lr_stacking))))\n",
    "pred_list['test_preds_lr_stacking'] = test_preds_lr_stacking\n",
    "if Validation:\n",
    "    print('Test R-squared for %s is %f' %('test_preds_lr_stacking', sqrt(mean_squared_error(y_test_level2, test_preds_lr_stacking))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. Second level learning model via SGDRegressor\n",
    "print('Training Second level learning model via SGDRegressor')\n",
    "sgdr= SGDRegressor(\n",
    "    penalty = 'l2' ,\n",
    "    random_state = SEED )\n",
    "sgdr.fit(X_train_level2, y_train_level2)\n",
    "# Compute R-squared on the train and test sets.\n",
    "# print('Train R-squared for %s is %f' %('test_preds_lr_stacking', sqrt(mean_squared_error(y_train_level2, lr.predict(X_train_level2)))))\n",
    "test_preds_sgdr_stacking = sgdr.predict(X_test_level2)\n",
    "train_preds_sgdr_stacking = sgdr.predict(X_train_level2)\n",
    "print('Train R-squared for %s is %f' %('train_preds_lr_stacking', sqrt(mean_squared_error(y_train_level2, train_preds_sgdr_stacking))))\n",
    "pred_list['test_preds_sgdr_stacking'] = test_preds_sgdr_stacking\n",
    "if Validation:\n",
    "    print('Test R-squared for %s is %f' %('test_preds_sgdr_stacking', sqrt(mean_squared_error(y_test_level2, test_preds_sgdr_stacking))))\n",
    "print('%0.2f min: Finish training second level model'%((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission -------------------------------------------------------------------\n",
    "if not Validation:\n",
    "    submission = pd.read_csv('../data/sample_submission.csv')\n",
    "    ver = 6\n",
    "    for pred_ver in ['lr_stacking', 'sgdr_stacking']:\n",
    "        print(pred_list['test_preds_' + pred_ver].clip(0,20).mean())\n",
    "        submission['item_cnt_month'] = pred_list['test_preds_' + pred_ver].clip(0,20)\n",
    "        submission[['ID', 'item_cnt_month']].to_csv(\"../results/09/09.csv\", index = False)\n",
    "print('%0.2f min: Finish running scripts'%((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!shutdown -s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
