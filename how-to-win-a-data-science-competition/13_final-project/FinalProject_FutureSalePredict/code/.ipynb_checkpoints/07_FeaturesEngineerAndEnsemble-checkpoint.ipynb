{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from numpy import loadtxt\n",
    "import time\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')\n",
    "kernel_with_output = True\n",
    "np.random.seed(10)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option('display.max_rows', 231)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Validation = False\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    # Feature engineering list\n",
    "    new_features = []\n",
    "    enable_feature_idea = [True, True, True, True, True, True, True, True, True, True]\n",
    "    # Some parameters(maybe add more periods, score will be better) [1,2,3,12]\n",
    "    lookback_range = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "    tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype in [\"int64\", \"int32\"]]\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int16)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    item =pd.read_csv(\"../data/items.csv\")\n",
    "    item_cat = pd.read_csv(\"../data/item_categories.csv\")\n",
    "#     df_shops = pd.read_csv(\"../data/shops.csv\")\n",
    "    sale_train = pd.read_csv(\"../data/sales_train.csv\")\n",
    "    test = pd.read_csv(\"../data/test.csv\")\n",
    "    temp = pd.read_csv(\"../data/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              28.10.2015\n",
       "date_block_num            33\n",
       "shop_id                   12\n",
       "item_id                11373\n",
       "item_price          0.908714\n",
       "item_cnt_day            2169\n",
       "Name: 2909818, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_train.loc[2909818] # id = 2909818 seems outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_train['item_price'][2909818] = sale_train[(sale_train['shop_id'] ==12) & (sale_train['item_id'] == 11373) & (sale_train['date_block_num'] == 33)]['item_price'].median()\n",
    "sale_train['item_cnt_day'][2909818] = round(sale_train[(sale_train['shop_id'] ==12) & (sale_train['item_id'] == 11373) & (sale_train['date_block_num'] == 33)]['item_cnt_day'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              28.10.2015\n",
       "date_block_num            33\n",
       "shop_id                   12\n",
       "item_id                11373\n",
       "item_price               317\n",
       "item_cnt_day               4\n",
       "Name: 2909818, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_train.loc[2909818] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              17.09.2013\n",
       "date_block_num             8\n",
       "shop_id                   12\n",
       "item_id                11365\n",
       "item_price             59200\n",
       "item_cnt_day               1\n",
       "Name: 885138, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_train.loc[885138] # the price seems too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_train['item_price'][885138] = sale_train[(sale_train['item_id'] == 11365) & (sale_train['shop_id'] ==12) & (sale_train['date_block_num'] == 8)]['item_price'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              17.09.2013\n",
       "date_block_num             8\n",
       "shop_id                   12\n",
       "item_id                11365\n",
       "item_price              2770\n",
       "item_cnt_day               1\n",
       "Name: 885138, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_train.loc[885138] # the price seems too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2935849, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nrow = test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sale_train = sale_train.merge(test[['shop_id']].drop_duplicates(), how = 'inner') \n",
    "sale_train['date'] = pd.to_datetime(sale_train['date'], format = '%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After merge, we delete 522603 records from sale_train. The reason is we want drop all transactions belong to shops in the train set but not in the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2413246 entries, 0 to 2413245\n",
      "Data columns (total 6 columns):\n",
      "date              datetime64[ns]\n",
      "date_block_num    int64\n",
      "shop_id           int64\n",
      "item_id           int64\n",
      "item_price        float64\n",
      "item_cnt_day      float64\n",
      "dtypes: datetime64[ns](1), float64(2), int64(3)\n",
      "memory usage: 128.9 MB\n"
     ]
    }
   ],
   "source": [
    "sale_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 steps:\n",
    "\n",
    "(1) Aggregate data\n",
    "\n",
    "(2) Add item/shop pair mean-encoding\n",
    "\n",
    "(3) First-level model\n",
    "\n",
    "(4) Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Aggregate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = []\n",
    "for block_num in sale_train['date_block_num'].unique():\n",
    "    cur_shops = sale_train[sale_train['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sale_train[sale_train['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(itertools.product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "print('%0.2f min: Finish creating the grid'%((time.time() - start_time)/60))\n",
    "\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "sale_train['item_cnt_day'] = sale_train['item_cnt_day'].clip(0,20)\n",
    "# gb_cnt = sale_train.groupby(index_cols)['item_cnt_day'].agg(['sum']).reset_index().rename(columns = {'sum': 'item_cnt_month'})\n",
    "gb_cnt = sale_train.groupby(index_cols).agg({\"item_cnt_day\":\"sum\", \"item_price\":\"mean\"}).reset_index()\n",
    "gb_cnt.rename({\"item_cnt_day\":\"item_cnt_month\"}, inplace = True, axis = \"columns\")\n",
    "gb_cnt['item_cnt_month'] = gb_cnt['item_cnt_month'].clip(0,20).astype(np.int)\n",
    "#join aggregated data to the grid\n",
    "train = pd.merge(grid,gb_cnt,how='left',on=index_cols).fillna(0)\n",
    "train['item_cnt_month'] = train['item_cnt_month'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(item[['item_id', 'item_category_id']], on = ['item_id'], how = 'left')\n",
    "test = test.merge(item[[\"item_id\", \"item_category_id\"]], on = [\"item_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cat.head()\n",
    "item_cat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_cat = pd.read_csv('../data/item_categories.csv')\n",
    "\n",
    "l_cat = list(item_cat.item_category_name)\n",
    "\n",
    "for ind in range(0,1):\n",
    "\n",
    "    l_cat[ind] = 'PC Headsets / Headphones'\n",
    "\n",
    "for ind in range(1,8):\n",
    "\n",
    "    l_cat[ind] = 'Access'\n",
    "\n",
    "l_cat[8] = 'Tickets (figure)'\n",
    "\n",
    "l_cat[9] = 'Delivery of goods'\n",
    "\n",
    "for ind in range(10,18):\n",
    "\n",
    "    l_cat[ind] = 'Consoles'\n",
    "\n",
    "for ind in range(18,25):\n",
    "\n",
    "    l_cat[ind] = 'Consoles Games'\n",
    "\n",
    "l_cat[25] = 'Accessories for games'\n",
    "\n",
    "for ind in range(26,28):\n",
    "\n",
    "    l_cat[ind] = 'phone games'\n",
    "\n",
    "for ind in range(28,32):\n",
    "\n",
    "    l_cat[ind] = 'CD games'\n",
    "\n",
    "for ind in range(32,37):\n",
    "\n",
    "    l_cat[ind] = 'Card'\n",
    "\n",
    "for ind in range(37,43):\n",
    "\n",
    "    l_cat[ind] = 'Movie'\n",
    "\n",
    "for ind in range(43,55):\n",
    "\n",
    "    l_cat[ind] = 'Books'\n",
    "\n",
    "for ind in range(55,61):\n",
    "\n",
    "    l_cat[ind] = 'Music'\n",
    "\n",
    "for ind in range(61,73):\n",
    "\n",
    "    l_cat[ind] = 'Gifts'\n",
    "\n",
    "for ind in range(73,79):\n",
    "\n",
    "    l_cat[ind] = 'Soft'\n",
    "\n",
    "for ind in range(79,81):\n",
    "\n",
    "    l_cat[ind] = 'Office'\n",
    "\n",
    "for ind in range(81,83):\n",
    "\n",
    "    l_cat[ind] = 'Clean'\n",
    "\n",
    "l_cat[83] = 'Elements of a food'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lb = preprocessing.LabelEncoder()\n",
    "item_cat['item_cat_id_fix'] = lb.fit_transform(l_cat)\n",
    "train = train.merge(item_cat[['item_cat_id_fix', 'item_category_id']], on = ['item_category_id'], how = 'left')\n",
    "test = test.merge(item_cat[['item_cat_id_fix', 'item_category_id']], on = ['item_category_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item_cat.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = downcast_dtypes(train)\n",
    "test = downcast_dtypes(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Add item/shop pair mean-encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Combine trainset and testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%0.2f min: Start combining data'%((time.time() - start_time)/60))\n",
    "if Validation == False:\n",
    "    test['date_block_num'] = 34\n",
    "    all_data = pd.concat([train, test], axis = 0)\n",
    "    all_data = all_data.drop(columns = ['ID'])\n",
    "else:\n",
    "    all_data = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape\n",
    "all_data.isnull().sum() # test has only 5 cols, so when merge, these cols will be na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = downcast_dtypes(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.to_pickle(\"../results/07/all_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if kernel_with_output:\n",
    "    current = time.time()\n",
    "    trainset = pd.read_pickle(\"../results/07/all_data.pkl\")\n",
    "    items = pd.read_csv('../data/items.csv')\n",
    "    shops = pd.read_csv('../data/shops.csv')\n",
    "    # Only use more recent data\n",
    "    start_month = 0\n",
    "    end_month = 33\n",
    "    trainset = trainset[['shop_id', 'item_id', 'item_category_id', 'date_block_num', 'item_price', 'item_cnt_month']]\n",
    "    trainset = trainset[(trainset.date_block_num >= start_month) & (trainset.date_block_num <= end_month)]\n",
    "\n",
    "    print('Loading test set...')\n",
    "    test_dataset = loadtxt('../data/test.csv', delimiter=\",\" ,skiprows=1, usecols = (1,2), dtype=int)\n",
    "    testset = pd.DataFrame(test_dataset, columns = ['shop_id', 'item_id'])\n",
    "\n",
    "    print('Merging with other datasets...')\n",
    "    # Get item category id into test_df\n",
    "    testset = testset.merge(items[['item_id', 'item_category_id']], on = 'item_id', how = 'left')\n",
    "    testset['date_block_num'] = 34\n",
    "    # Make testset contains same column as trainset so we can concatenate them row-wise\n",
    "    testset['item_cnt_month'] = -1\n",
    "\n",
    "    train_test_set = pd.concat([trainset, testset], axis = 0) \n",
    "    \n",
    "    end = time.time()\n",
    "    diff = end - current\n",
    "    print('Took ' + str(int(diff)) + ' seconds to train and predict val set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 0: Add previous shop/item sales as feature (Lag feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add the sales of this item of this shop in i previous months, i = loopback_range\n",
    "if kernel_with_output:\n",
    "    if enable_feature_idea[0]:\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_shopitem_sales_' + str(diff)\n",
    "            trainset2 = train_test_set.copy()\n",
    "            trainset2.loc[:, 'date_block_num'] += diff\n",
    "            trainset2.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(trainset2[['shop_id', 'item_id', 'date_block_num', feature_name]], on = ['shop_id', 'item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 1: Add previous item sales as feature (Lag feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add the everage of sales of an item in i previous month, ie.\n",
    "# row item_id = 0, date_block_num = 21, then add a column prev_item_sales_1(the average of sales of item_id = 0 in date_block_num=20) \n",
    "if kernel_with_output:\n",
    "    if enable_feature_idea[1]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_item_sales_' + str(diff)\n",
    "            result = groups.agg({'item_cnt_month':'mean'})\n",
    "            result = result.reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)\n",
    "train_test_set.to_pickle(\"../results/07/all_data_traintest_01.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 2: Add previous shop/item price as feature (Lag feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add the everage of the price of this item of this shop in i previous months\n",
    "if kernel_with_output:\n",
    "    if enable_feature_idea[2]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'shop_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_shopitem_price_' + str(diff)\n",
    "            result = groups.agg({'item_price':'mean'}).reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_price': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'shop_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)\n",
    "train_test_set.to_pickle(\"../results/07/all_data_traintest_012.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 3: Add previous item price as feature (Lag feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the everage of the price of this item in i previous months (not care abt shops)\n",
    "if kernel_with_output:\n",
    "    if enable_feature_idea[3]:\n",
    "        groups = train_test_set.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = 'prev_item_price_' + str(diff)\n",
    "            result = groups.agg({'item_price':'mean'}).reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_price': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        \n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)\n",
    "train_test_set.to_pickle(\"../results/07/all_data_traintest_0123.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 4: mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = pd.read_pickle(\"../results/07/all_data_traintest_0123.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_encodings(train_test_set, categorical_var_list, target):\n",
    "    feature_name = \"_\".join(categorical_var_list) + \"_\" + target + \"_mean\"\n",
    "\n",
    "    df = train_test_set.copy()\n",
    "    df1 = df[df.date_block_num <= 32]\n",
    "    df2 = df[df.date_block_num <= 33]\n",
    "    df3 = df[df.date_block_num == 34]\n",
    "\n",
    "    # Extract mean encodings using training data(here we don't use month 33 to avoid data leak on validation)\n",
    "    # If I try to extract mean encodings from all months, then val rmse decreases a tiny bit, but test rmse would increase by 4%\n",
    "    # So this is important\n",
    "    mean_32 = df1[categorical_var_list + [target]].groupby(categorical_var_list, as_index=False)[[target]].mean()\n",
    "    mean_32 = mean_32.rename(columns={target:feature_name})\n",
    "\n",
    "    # Extract mean encodings using all data, this will be applied to test data\n",
    "    mean_33 = df2[categorical_var_list + [target]].groupby(categorical_var_list, as_index=False)[[target]].mean()\n",
    "    mean_33 = mean_33.rename(columns={target:feature_name})\n",
    "\n",
    "    # Apply mean encodings\n",
    "    df2 = df2.merge(mean_32, on = categorical_var_list, how = 'left')\n",
    "    df3 = df3.merge(mean_33, on = categorical_var_list, how = 'left')\n",
    "\n",
    "    # Concatenate\n",
    "    train_test_set = pd.concat([df2, df3], axis = 0)\n",
    "    new_features.append(feature_name)\n",
    "    return train_test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>prev_shopitem_sales_1</th>\n",
       "      <th>prev_shopitem_sales_2</th>\n",
       "      <th>prev_shopitem_sales_3</th>\n",
       "      <th>prev_shopitem_sales_4</th>\n",
       "      <th>prev_shopitem_sales_5</th>\n",
       "      <th>prev_shopitem_sales_6</th>\n",
       "      <th>prev_shopitem_sales_7</th>\n",
       "      <th>prev_shopitem_sales_8</th>\n",
       "      <th>prev_shopitem_sales_9</th>\n",
       "      <th>prev_shopitem_sales_10</th>\n",
       "      <th>prev_shopitem_sales_11</th>\n",
       "      <th>prev_shopitem_sales_12</th>\n",
       "      <th>prev_item_sales_1</th>\n",
       "      <th>prev_item_sales_2</th>\n",
       "      <th>prev_item_sales_3</th>\n",
       "      <th>prev_item_sales_4</th>\n",
       "      <th>prev_item_sales_5</th>\n",
       "      <th>prev_item_sales_6</th>\n",
       "      <th>prev_item_sales_7</th>\n",
       "      <th>prev_item_sales_8</th>\n",
       "      <th>prev_item_sales_9</th>\n",
       "      <th>prev_item_sales_10</th>\n",
       "      <th>prev_item_sales_11</th>\n",
       "      <th>prev_item_sales_12</th>\n",
       "      <th>prev_shopitem_price_1</th>\n",
       "      <th>prev_shopitem_price_2</th>\n",
       "      <th>prev_shopitem_price_3</th>\n",
       "      <th>prev_shopitem_price_4</th>\n",
       "      <th>prev_shopitem_price_5</th>\n",
       "      <th>prev_shopitem_price_6</th>\n",
       "      <th>prev_shopitem_price_7</th>\n",
       "      <th>prev_shopitem_price_8</th>\n",
       "      <th>prev_shopitem_price_9</th>\n",
       "      <th>prev_shopitem_price_10</th>\n",
       "      <th>prev_shopitem_price_11</th>\n",
       "      <th>prev_shopitem_price_12</th>\n",
       "      <th>prev_item_price_1</th>\n",
       "      <th>prev_item_price_2</th>\n",
       "      <th>prev_item_price_3</th>\n",
       "      <th>prev_item_price_4</th>\n",
       "      <th>prev_item_price_5</th>\n",
       "      <th>prev_item_price_6</th>\n",
       "      <th>prev_item_price_7</th>\n",
       "      <th>prev_item_price_8</th>\n",
       "      <th>prev_item_price_9</th>\n",
       "      <th>prev_item_price_10</th>\n",
       "      <th>prev_item_price_11</th>\n",
       "      <th>prev_item_price_12</th>\n",
       "      <th>shop_id_item_id_item_cnt_month_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22151</td>\n",
       "      <td>399.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5603</td>\n",
       "      <td>699.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_category_id  item_cnt_month  item_id  item_price  \\\n",
       "0               0                37             1.0    22154       999.0   \n",
       "1               0                40             2.0    22151       399.0   \n",
       "2               0                 5             1.0     5603       699.0   \n",
       "\n",
       "   shop_id  prev_shopitem_sales_1  prev_shopitem_sales_2  \\\n",
       "0       59                    0.0                    0.0   \n",
       "1       59                    0.0                    0.0   \n",
       "2       59                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_3  prev_shopitem_sales_4  prev_shopitem_sales_5  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_6  prev_shopitem_sales_7  prev_shopitem_sales_8  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_9  prev_shopitem_sales_10  prev_shopitem_sales_11  \\\n",
       "0                    0.0                     0.0                     0.0   \n",
       "1                    0.0                     0.0                     0.0   \n",
       "2                    0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_shopitem_sales_12  prev_item_sales_1  prev_item_sales_2  \\\n",
       "0                     0.0                0.0                0.0   \n",
       "1                     0.0                0.0                0.0   \n",
       "2                     0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_3  prev_item_sales_4  prev_item_sales_5  prev_item_sales_6  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_7  prev_item_sales_8  prev_item_sales_9  \\\n",
       "0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_10  prev_item_sales_11  prev_item_sales_12  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "\n",
       "   prev_shopitem_price_1  prev_shopitem_price_2  prev_shopitem_price_3  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_4  prev_shopitem_price_5  prev_shopitem_price_6  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_7  prev_shopitem_price_8  prev_shopitem_price_9  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_10  prev_shopitem_price_11  prev_shopitem_price_12  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_item_price_1  prev_item_price_2  prev_item_price_3  prev_item_price_4  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_price_5  prev_item_price_6  prev_item_price_7  prev_item_price_8  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_price_9  prev_item_price_10  prev_item_price_11  \\\n",
       "0                0.0                 0.0                 0.0   \n",
       "1                0.0                 0.0                 0.0   \n",
       "2                0.0                 0.0                 0.0   \n",
       "\n",
       "   prev_item_price_12  shop_id_item_id_item_cnt_month_mean  \n",
       "0                 0.0                             0.090909  \n",
       "1                 0.0                             0.428571  \n",
       "2                 0.0                             0.100000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if kernel_with_output:\n",
    "    train_test_set = create_mean_encodings(train_test_set, ['shop_id', 'item_id'], 'item_cnt_month')\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 5: Mean encodings for item (Mean encoding, doesnt work for me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>prev_shopitem_sales_1</th>\n",
       "      <th>prev_shopitem_sales_2</th>\n",
       "      <th>prev_shopitem_sales_3</th>\n",
       "      <th>prev_shopitem_sales_4</th>\n",
       "      <th>prev_shopitem_sales_5</th>\n",
       "      <th>prev_shopitem_sales_6</th>\n",
       "      <th>prev_shopitem_sales_7</th>\n",
       "      <th>prev_shopitem_sales_8</th>\n",
       "      <th>prev_shopitem_sales_9</th>\n",
       "      <th>prev_shopitem_sales_10</th>\n",
       "      <th>prev_shopitem_sales_11</th>\n",
       "      <th>prev_shopitem_sales_12</th>\n",
       "      <th>prev_item_sales_1</th>\n",
       "      <th>prev_item_sales_2</th>\n",
       "      <th>prev_item_sales_3</th>\n",
       "      <th>prev_item_sales_4</th>\n",
       "      <th>prev_item_sales_5</th>\n",
       "      <th>prev_item_sales_6</th>\n",
       "      <th>prev_item_sales_7</th>\n",
       "      <th>prev_item_sales_8</th>\n",
       "      <th>prev_item_sales_9</th>\n",
       "      <th>prev_item_sales_10</th>\n",
       "      <th>prev_item_sales_11</th>\n",
       "      <th>prev_item_sales_12</th>\n",
       "      <th>prev_shopitem_price_1</th>\n",
       "      <th>prev_shopitem_price_2</th>\n",
       "      <th>prev_shopitem_price_3</th>\n",
       "      <th>prev_shopitem_price_4</th>\n",
       "      <th>prev_shopitem_price_5</th>\n",
       "      <th>prev_shopitem_price_6</th>\n",
       "      <th>prev_shopitem_price_7</th>\n",
       "      <th>prev_shopitem_price_8</th>\n",
       "      <th>prev_shopitem_price_9</th>\n",
       "      <th>prev_shopitem_price_10</th>\n",
       "      <th>prev_shopitem_price_11</th>\n",
       "      <th>prev_shopitem_price_12</th>\n",
       "      <th>prev_item_price_1</th>\n",
       "      <th>prev_item_price_2</th>\n",
       "      <th>prev_item_price_3</th>\n",
       "      <th>prev_item_price_4</th>\n",
       "      <th>prev_item_price_5</th>\n",
       "      <th>prev_item_price_6</th>\n",
       "      <th>prev_item_price_7</th>\n",
       "      <th>prev_item_price_8</th>\n",
       "      <th>prev_item_price_9</th>\n",
       "      <th>prev_item_price_10</th>\n",
       "      <th>prev_item_price_11</th>\n",
       "      <th>prev_item_price_12</th>\n",
       "      <th>shop_id_item_id_item_cnt_month_mean</th>\n",
       "      <th>item_id_item_cnt_month_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.104623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22151</td>\n",
       "      <td>399.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5603</td>\n",
       "      <td>699.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.093664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_block_num  item_category_id  item_cnt_month  item_id  item_price  \\\n",
       "0               0                37             1.0    22154       999.0   \n",
       "1               0                40             2.0    22151       399.0   \n",
       "2               0                 5             1.0     5603       699.0   \n",
       "\n",
       "   shop_id  prev_shopitem_sales_1  prev_shopitem_sales_2  \\\n",
       "0       59                    0.0                    0.0   \n",
       "1       59                    0.0                    0.0   \n",
       "2       59                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_3  prev_shopitem_sales_4  prev_shopitem_sales_5  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_6  prev_shopitem_sales_7  prev_shopitem_sales_8  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_sales_9  prev_shopitem_sales_10  prev_shopitem_sales_11  \\\n",
       "0                    0.0                     0.0                     0.0   \n",
       "1                    0.0                     0.0                     0.0   \n",
       "2                    0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_shopitem_sales_12  prev_item_sales_1  prev_item_sales_2  \\\n",
       "0                     0.0                0.0                0.0   \n",
       "1                     0.0                0.0                0.0   \n",
       "2                     0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_3  prev_item_sales_4  prev_item_sales_5  prev_item_sales_6  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_7  prev_item_sales_8  prev_item_sales_9  \\\n",
       "0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_sales_10  prev_item_sales_11  prev_item_sales_12  \\\n",
       "0                 0.0                 0.0                 0.0   \n",
       "1                 0.0                 0.0                 0.0   \n",
       "2                 0.0                 0.0                 0.0   \n",
       "\n",
       "   prev_shopitem_price_1  prev_shopitem_price_2  prev_shopitem_price_3  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_4  prev_shopitem_price_5  prev_shopitem_price_6  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_7  prev_shopitem_price_8  prev_shopitem_price_9  \\\n",
       "0                    0.0                    0.0                    0.0   \n",
       "1                    0.0                    0.0                    0.0   \n",
       "2                    0.0                    0.0                    0.0   \n",
       "\n",
       "   prev_shopitem_price_10  prev_shopitem_price_11  prev_shopitem_price_12  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   prev_item_price_1  prev_item_price_2  prev_item_price_3  prev_item_price_4  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_price_5  prev_item_price_6  prev_item_price_7  prev_item_price_8  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   prev_item_price_9  prev_item_price_10  prev_item_price_11  \\\n",
       "0                0.0                 0.0                 0.0   \n",
       "1                0.0                 0.0                 0.0   \n",
       "2                0.0                 0.0                 0.0   \n",
       "\n",
       "   prev_item_price_12  shop_id_item_id_item_cnt_month_mean  \\\n",
       "0                 0.0                             0.090909   \n",
       "1                 0.0                             0.428571   \n",
       "2                 0.0                             0.100000   \n",
       "\n",
       "   item_id_item_cnt_month_mean  \n",
       "0                     0.104623  \n",
       "1                     0.856000  \n",
       "2                     0.093664  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if kernel_with_output:\n",
    "    train_test_set = create_mean_encodings(train_test_set, ['item_id'], 'item_cnt_month')\n",
    "    train_test_set.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 6: Number of month from last sale of shop/item (Use info from past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each item of each shop, find the last i months sales. \n",
    "def create_last_sale_shop_item(row):\n",
    "    for diff in range(1,33+1):\n",
    "        feature_name = '_prev_shopitem_sales_' + str(diff)\n",
    "        if row[feature_name] != 0.0:\n",
    "            return diff\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [06:14<00:00, 13.02s/it]\n"
     ]
    }
   ],
   "source": [
    "if kernel_with_output:\n",
    "    lookback_range = list(range(1, 33 + 1))\n",
    "    if enable_feature_idea[6]:\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = '_prev_shopitem_sales_' + str(diff)\n",
    "            trainset2 = train_test_set[[\"shop_id\", \"item_id\", \"date_block_num\", \"item_cnt_month\"]].copy()\n",
    "            trainset2.loc[:, 'date_block_num'] += diff\n",
    "            trainset2.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(trainset2[['shop_id', 'item_id', 'date_block_num', feature_name]], on = ['shop_id', 'item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            #new_features.append(feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 8812244/8812244 [21:50<00:00, 6723.13it/s]\n"
     ]
    }
   ],
   "source": [
    "train_test_set.loc[:, 'last_sale_shop_item'] = train_test_set.progress_apply (lambda row: create_last_sale_shop_item(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)\n",
    "train_test_set.to_pickle(\"../results/07/07_1/all_data_traintest_0123456.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea 7: Number of month from last sale of item(Use info from past)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set_temp = train_test_set[[\"item_id\", \"date_block_num\", \"item_cnt_month\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_last_sale_item(row):\n",
    "    for diff in range(1,33+1):\n",
    "        feature_name = '_prev_item_sales_' + str(diff)\n",
    "        if row[feature_name] != 0.0:\n",
    "            return diff\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [02:30<00:00,  5.20s/it]\n"
     ]
    }
   ],
   "source": [
    "if kernel_with_output:\n",
    "    lookback_range = list(range(1, 33 + 1))\n",
    "    if enable_feature_idea[1]:\n",
    "        groups = train_test_set_temp.groupby(by = ['item_id', 'date_block_num'])\n",
    "        for diff in tqdm(lookback_range):\n",
    "            feature_name = '_prev_item_sales_' + str(diff)\n",
    "            result = groups.agg({'item_cnt_month':'mean'}).reset_index()\n",
    "            result.loc[:, 'date_block_num'] += diff\n",
    "            result.rename(columns={'item_cnt_month': feature_name}, inplace=True)\n",
    "            train_test_set = train_test_set.merge(result, on = ['item_id', 'date_block_num'], how = 'left')\n",
    "            train_test_set[feature_name] = train_test_set[feature_name].fillna(0)\n",
    "            new_features.append(feature_name)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 8812244/8812244 [05:23<00:00, 27274.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_test_set.loc[:, 'last_sale_item'] = train_test_set.progress_apply (lambda row: create_last_sale_item(row),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = downcast_dtypes(train_test_set)\n",
    "train_test_set.to_pickle(\"../results/07/07_1/all_data_traintest_01234567.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_set.drop([\"Unnamed: 0\", \"Unnamed: 0.1\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set.loc[train_test_set.prev_item_sales_2==\"0*0\",\"prev_item_sales_2\"] = 0.0\n",
    "train_test_set.prev_item_sales_2 = train_test_set.prev_item_sales_2.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "[15:15:34] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:15:34] WARNING: src/learner.cc:686: Tree method is automatically selected to be 'approx' for faster speed. To use old behavior (exact greedy algorithm on single machine), set tree_method to 'exact'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0,\n",
       "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=11, min_child_weight=0.5, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=16, num_round=1000, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=1, silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if kernel_with_output:\n",
    "    current = time.time()\n",
    "\n",
    "    baseline_features = ['shop_id', 'item_id', 'item_category_id', 'date_block_num'] +  new_features + ['item_cnt_month']\n",
    "\n",
    "    # Clipping to range 0-20\n",
    "    train_test_set['item_cnt_month'] = train_test_set.item_cnt_month.fillna(0).clip(0,20)\n",
    "\n",
    "    # train: want rows with date_block_num from 0 to 31\n",
    "    train_time_range_lo = (train_test_set['date_block_num'] >= 0)\n",
    "    train_time_range_hi =  (train_test_set['date_block_num'] <= 32)\n",
    "\n",
    "    # val: want rows with date_block_num from 22\n",
    "    validation_time =  (train_test_set['date_block_num'] == 33)\n",
    "\n",
    "    # test: want rows with date_block_num from 34\n",
    "    test_time =  (train_test_set['date_block_num'] == 34)\n",
    "\n",
    "\n",
    "    # Retrieve rows for train set, val set, test set\n",
    "    cv_trainset = train_test_set[train_time_range_lo & train_time_range_hi]\n",
    "    cv_valset = train_test_set[validation_time]\n",
    "    cv_trainset = cv_trainset[baseline_features]\n",
    "    cv_valset = cv_valset[baseline_features]\n",
    "    testset = train_test_set[test_time]\n",
    "    testset = testset[baseline_features]\n",
    "\n",
    "    # Prepare numpy arrays for training/val/test\n",
    "    cv_trainset_vals = cv_trainset.values.astype(int)\n",
    "    trainx = cv_trainset_vals[:, 0:len(baseline_features) - 1]\n",
    "    trainy = cv_trainset_vals[:, len(baseline_features) - 1]\n",
    "\n",
    "    cv_valset_vals = cv_valset.values.astype(int)\n",
    "    valx = cv_valset_vals[:, 0:len(baseline_features) - 1]\n",
    "    valy = cv_valset_vals[:, len(baseline_features) - 1]\n",
    "\n",
    "    testset_vals = testset.values.astype(int)\n",
    "    testx = testset_vals[:, 0:len(baseline_features) - 1]\n",
    "\n",
    "    print('Fitting...')\n",
    "    model = xgb.XGBRegressor(max_depth = 11, min_child_weight=0.5, subsample = 1, eta = 0.3, num_round = 1000, seed = 1, nthread = 16)\n",
    "    model.fit(trainx, trainy, eval_metric='rmse')\n",
    "\n",
    "\n",
    "    preds = model.predict(valx)\n",
    "    # Clipping to range 0-20\n",
    "    preds = np.clip(preds, 0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val set rmse:  0.9305994642913349\n",
      "test predictions written to file\n",
      "Took 986 seconds to train and predict val, test set\n"
     ]
    }
   ],
   "source": [
    "    from sklearn.metrics import mean_squared_error\n",
    "    print('val set rmse: ', np.sqrt(mean_squared_error(valy, preds)))\n",
    "\n",
    "    preds = model.predict(testx)\n",
    "    # Clipping to range 0-20\n",
    "    preds = np.clip(preds, 0,20)\n",
    "    df = pd.DataFrame(preds, columns = ['item_cnt_month'])\n",
    "    df['ID'] = df.index\n",
    "    df = df.set_index('ID')\n",
    "    df.to_csv('../results/07/07_1.csv')\n",
    "    print('test predictions written to file')\n",
    "\n",
    "    end = time.time()\n",
    "    diff = end - current\n",
    "    print('Took ' + str(int(diff)) + ' seconds to train and predict val, test set')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
